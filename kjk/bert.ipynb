{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertConfig, BertForSequenceClassification\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "import re\n",
    "\n",
    "# tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\") # Bert-base의 토크나이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6734 entries, 0 to 6733\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   content    6734 non-null   object\n",
      " 1   keyword    6734 non-null   object\n",
      " 2   title      6734 non-null   object\n",
      " 3   url        6734 non-null   object\n",
      " 4   writed_at  6734 non-null   object\n",
      " 5   writer     6612 non-null   object\n",
      "dtypes: object(6)\n",
      "memory usage: 315.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('./data_in_title.csv', dtype=object, encoding='utf-8')\n",
    "data.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bert-base 다국어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = data.content.values[0]\n",
    "sentences = sent_tokenize(text)\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\", do_lower_case=False)\n",
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = pad_sequences(input_ids, maxlen=64, dtype='long', truncating='post', padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   141, 118857,    117,   8997,  15001, 119412,  37388,  14040,\n",
       "         9258,  52363,  10892,  63042,  11204,    110,    117,  10413,\n",
       "          110,   1792,    120,   2104,   9901,  98511,  12692,   8896,\n",
       "        13890,    123,  37712,  12310,  23607,  10954,   9251,   9543,\n",
       "        21386,  21275,  35506,  10739, 118766,  12605,   9638,  38631,\n",
       "         9405,  26784,  13890,    119,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertConfig, BertForSequenceClassification\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# 학습 데이터셋을 TensorDataset으로 변환\n",
    "train_dataset = TensorDataset(torch.tensor(input_ids_train),\n",
    "                              torch.tensor(attention_masks_train),\n",
    "                              torch.tensor(labels_train))\n",
    "\n",
    "# 학습 데이터셋을 랜덤 샘플러로 사용하여 데이터 로더 생성\n",
    "train_sampler = RandomSampler(train_dataset)\n",
    "train_dataloader = DataLoader(train_dataset,\n",
    "                              sampler=train_sampler,\n",
    "                              batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = len(train_dataloader) * 10)\n",
    "\n",
    "for i in range(10):\n",
    "    total_loss = 0\n",
    "    # 모델을 학습모드로 변경\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # 500 스텝마다 시간 출력\n",
    "        # if step % 500 == 0 and not step == 0:\n",
    "        #     elapsed = format_time(time.time()- t0)\n",
    "        \n",
    "        # batch의 데이터를 device에 올림\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        outputs = model(b_input_ids,\n",
    "                        token_type_ids=None,\n",
    "                        attention_mask=b_input_mask,\n",
    "                        labels=b_labels)\n",
    "        loss = outputs[0]\n",
    "        total_loss += loss\n",
    "        loss.backward()# loss 기울기 계산\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)# 기울기 폭발 방지\n",
    "        optimizer.step()# 파라미터 업데이트\n",
    "        scheduler.step()# 학습률 업데이트\n",
    "        model.zero_grad()# 기울기 초기화\n",
    "    avg_train_loss = total_loss / len(train_dataloader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kr-finbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"snunlp/KR-FinBert-SC\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"snunlp/KR-FinBert-SC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D램, 낸드플래시 매출은 각각 37%, 31% ↓ / 中 파운드리 공장 2분기 2020년 말 양산 \\nSK하이닉스 이천 사업장.',\n",
       " '연합뉴스 SK하이닉스의 지난해 매출액이 전년 대비 33% 감소했지만, 비메모리 반도체 매출은 50%가량 증가한 것으로 나타났다.',\n",
       " '31일 SK하이닉스의 사업보고서에 따르면, 2019년 D램 매출은 20조3000억원으로 전년과 비교해 37% 감소했고, 낸드플래시 매출은 5조1000억원으로 31% 줄어든 것으로 집계됐다.',\n",
       " '반면 비메모리 사업을 포함한 기타 항목 매출은 2018년 6500억원에서 지난해 1조6000억원으로 2배 이상 증가했다.',\n",
       " '지난해 기타 매출 가운데는 SK하이닉스가 2018년 12월 지분 100%를 인수한 사회적기업 행복나래 등 자회사 매출 약 7000억원이 포함됐다.',\n",
       " '나머지 매출 약 8000억원은 이미지센서 부문과 파운드리 자회사 SK하이닉스시스템IC 등 비메모리 반도체 사업으로, 2018년(5500억여원) 대비 성장한 것으로 파악된다.',\n",
       " '이에 따라 D램 부문 매출 비중은 2018년 80%에서 지난해 75%로 줄어들었고, 기타 항목 비중은 같은 기간 2%에서 6%로 확대됐다.',\n",
       " 'SK하이닉스가 주력하는 분야는 비메모리 사업 중에서도 모바일, 노트북용 이미지센서 시장이다.',\n",
       " '지난해 일본에 차세대 CIS(CMOS 이미지센서) 연구개발센터를 여는 등 시장 점유율 확대를 위한 제품 개발에 주력하고 있다.',\n",
       " \"올해는 모든 CIS 제품을 '블랙펄(Black Pearl)'로 공식 브랜딩하고, 하반기 중 픽셀 크기로 4800만화소를 구현한 제품도 선보인다는 계획이다.\",\n",
       " 'SK하이닉스시스템IC는 중국 장쑤성 우시에서 합작법인을 설립해 파운드리 공장을 건설하고 있다.',\n",
       " '올해 2분기 내 준공되면 연말 양산이 목표다.',\n",
       " 'SK하이닉스는 이날 매그나칩반도체의 파운드리(반도체 위탁생산) 부문도 인수했다.',\n",
       " '박세준 기자 세상을 보는 눈, 세계일보']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = data.content.values[0]\n",
    "sentences = sent_tokenize(text)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "\n",
    "input_ids = pad_sequences(input_ids, maxlen=128, dtype='long', truncating='post', padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['D',\n",
       "  '##램',\n",
       "  ',',\n",
       "  '낸',\n",
       "  '##드',\n",
       "  '##플',\n",
       "  '##래',\n",
       "  '##시',\n",
       "  '매출',\n",
       "  '##은',\n",
       "  '각각',\n",
       "  '37',\n",
       "  '%',\n",
       "  ',',\n",
       "  '31',\n",
       "  '%',\n",
       "  '↓',\n",
       "  '/',\n",
       "  '中',\n",
       "  '파',\n",
       "  '##운드',\n",
       "  '##리',\n",
       "  '공장',\n",
       "  '2',\n",
       "  '##분기',\n",
       "  '2020년',\n",
       "  '말',\n",
       "  '양산',\n",
       "  'SK',\n",
       "  '##하이',\n",
       "  '##닉',\n",
       "  '##스',\n",
       "  '이',\n",
       "  '##천',\n",
       "  '사업',\n",
       "  '##장',\n",
       "  '.'],\n",
       " ['연합',\n",
       "  '##뉴스',\n",
       "  'SK',\n",
       "  '##하이',\n",
       "  '##닉',\n",
       "  '##스의',\n",
       "  '지난해',\n",
       "  '매출',\n",
       "  '##액이',\n",
       "  '전년',\n",
       "  '대비',\n",
       "  '33',\n",
       "  '%',\n",
       "  '감소',\n",
       "  '##했지만',\n",
       "  ',',\n",
       "  '비',\n",
       "  '##메',\n",
       "  '##모',\n",
       "  '##리',\n",
       "  '반도체',\n",
       "  '매출',\n",
       "  '##은',\n",
       "  '50',\n",
       "  '%',\n",
       "  '가',\n",
       "  '##량',\n",
       "  '증가',\n",
       "  '##한',\n",
       "  '것으로',\n",
       "  '나타났다',\n",
       "  '.'],\n",
       " ['31일',\n",
       "  'SK',\n",
       "  '##하이',\n",
       "  '##닉',\n",
       "  '##스의',\n",
       "  '사업',\n",
       "  '##보고',\n",
       "  '##서에',\n",
       "  '따르면',\n",
       "  ',',\n",
       "  '2019년',\n",
       "  'D',\n",
       "  '##램',\n",
       "  '매출',\n",
       "  '##은',\n",
       "  '20',\n",
       "  '##조',\n",
       "  '##30',\n",
       "  '##00',\n",
       "  '##억원',\n",
       "  '##으로',\n",
       "  '전년',\n",
       "  '##과',\n",
       "  '비교',\n",
       "  '##해',\n",
       "  '37',\n",
       "  '%',\n",
       "  '감소',\n",
       "  '##했고',\n",
       "  ',',\n",
       "  '낸',\n",
       "  '##드',\n",
       "  '##플',\n",
       "  '##래',\n",
       "  '##시',\n",
       "  '매출',\n",
       "  '##은',\n",
       "  '5',\n",
       "  '##조',\n",
       "  '##100',\n",
       "  '##0',\n",
       "  '##억원',\n",
       "  '##으로',\n",
       "  '31',\n",
       "  '%',\n",
       "  '줄어',\n",
       "  '##든',\n",
       "  '것으로',\n",
       "  '집계',\n",
       "  '##됐다',\n",
       "  '.'],\n",
       " ['반면',\n",
       "  '비',\n",
       "  '##메',\n",
       "  '##모',\n",
       "  '##리',\n",
       "  '사업을',\n",
       "  '포함한',\n",
       "  '기타',\n",
       "  '항',\n",
       "  '##목',\n",
       "  '매출',\n",
       "  '##은',\n",
       "  '2018년',\n",
       "  '65',\n",
       "  '##00',\n",
       "  '##억원',\n",
       "  '##에서',\n",
       "  '지난해',\n",
       "  '1조',\n",
       "  '##60',\n",
       "  '##00',\n",
       "  '##억원',\n",
       "  '##으로',\n",
       "  '2',\n",
       "  '##배',\n",
       "  '이상',\n",
       "  '증가',\n",
       "  '##했다',\n",
       "  '.'],\n",
       " ['지난해',\n",
       "  '기타',\n",
       "  '매출',\n",
       "  '가운데',\n",
       "  '##는',\n",
       "  'SK',\n",
       "  '##하이',\n",
       "  '##닉',\n",
       "  '##스가',\n",
       "  '2018년',\n",
       "  '12월',\n",
       "  '지분',\n",
       "  '100',\n",
       "  '%',\n",
       "  '를',\n",
       "  '인수',\n",
       "  '##한',\n",
       "  '사회적',\n",
       "  '##기업',\n",
       "  '행복',\n",
       "  '##나',\n",
       "  '##래',\n",
       "  '등',\n",
       "  '자',\n",
       "  '##회사',\n",
       "  '매출',\n",
       "  '약',\n",
       "  '70',\n",
       "  '##00',\n",
       "  '##억원',\n",
       "  '##이',\n",
       "  '포함',\n",
       "  '##됐다',\n",
       "  '.'],\n",
       " ['나머지',\n",
       "  '매출',\n",
       "  '약',\n",
       "  '800',\n",
       "  '##0',\n",
       "  '##억원',\n",
       "  '##은',\n",
       "  '이미지',\n",
       "  '##센',\n",
       "  '##서',\n",
       "  '부문',\n",
       "  '##과',\n",
       "  '파',\n",
       "  '##운드',\n",
       "  '##리',\n",
       "  '자',\n",
       "  '##회사',\n",
       "  'SK',\n",
       "  '##하이',\n",
       "  '##닉',\n",
       "  '##스',\n",
       "  '##시스템',\n",
       "  '##I',\n",
       "  '##C',\n",
       "  '등',\n",
       "  '비',\n",
       "  '##메',\n",
       "  '##모',\n",
       "  '##리',\n",
       "  '반도체',\n",
       "  '사업',\n",
       "  '##으로',\n",
       "  ',',\n",
       "  '2018년',\n",
       "  '(',\n",
       "  '55',\n",
       "  '##00',\n",
       "  '##억',\n",
       "  '##여',\n",
       "  '##원',\n",
       "  ')',\n",
       "  '대비',\n",
       "  '성장',\n",
       "  '##한',\n",
       "  '것으로',\n",
       "  '파악',\n",
       "  '##된다',\n",
       "  '.'],\n",
       " ['이에',\n",
       "  '따라',\n",
       "  'D',\n",
       "  '##램',\n",
       "  '부문',\n",
       "  '매출',\n",
       "  '비중',\n",
       "  '##은',\n",
       "  '2018년',\n",
       "  '80',\n",
       "  '%',\n",
       "  '에서',\n",
       "  '지난해',\n",
       "  '75',\n",
       "  '%',\n",
       "  '로',\n",
       "  '줄어들',\n",
       "  '##었고',\n",
       "  ',',\n",
       "  '기타',\n",
       "  '항',\n",
       "  '##목',\n",
       "  '비중',\n",
       "  '##은',\n",
       "  '같은',\n",
       "  '기간',\n",
       "  '2',\n",
       "  '%',\n",
       "  '에서',\n",
       "  '6',\n",
       "  '%',\n",
       "  '로',\n",
       "  '확대',\n",
       "  '##됐다',\n",
       "  '.'],\n",
       " ['SK',\n",
       "  '##하이',\n",
       "  '##닉',\n",
       "  '##스가',\n",
       "  '주',\n",
       "  '##력',\n",
       "  '##하는',\n",
       "  '분야',\n",
       "  '##는',\n",
       "  '비',\n",
       "  '##메',\n",
       "  '##모',\n",
       "  '##리',\n",
       "  '사업',\n",
       "  '중에서',\n",
       "  '##도',\n",
       "  '모바일',\n",
       "  ',',\n",
       "  '노트',\n",
       "  '##북',\n",
       "  '##용',\n",
       "  '이미지',\n",
       "  '##센',\n",
       "  '##서',\n",
       "  '시장이',\n",
       "  '##다',\n",
       "  '.'],\n",
       " ['지난해',\n",
       "  '일본에',\n",
       "  '차',\n",
       "  '##세대',\n",
       "  'C',\n",
       "  '##I',\n",
       "  '##S',\n",
       "  '(',\n",
       "  'C',\n",
       "  '##M',\n",
       "  '##O',\n",
       "  '##S',\n",
       "  '이미지',\n",
       "  '##센',\n",
       "  '##서',\n",
       "  ')',\n",
       "  '연구',\n",
       "  '##개발',\n",
       "  '##센터',\n",
       "  '##를',\n",
       "  '여',\n",
       "  '##는',\n",
       "  '등',\n",
       "  '시장',\n",
       "  '점유',\n",
       "  '##율',\n",
       "  '확대',\n",
       "  '##를',\n",
       "  '위한',\n",
       "  '제품',\n",
       "  '개발',\n",
       "  '##에',\n",
       "  '주',\n",
       "  '##력',\n",
       "  '##하고',\n",
       "  '있다',\n",
       "  '.'],\n",
       " ['올해',\n",
       "  '##는',\n",
       "  '모든',\n",
       "  'C',\n",
       "  '##I',\n",
       "  '##S',\n",
       "  '제품을',\n",
       "  \"'\",\n",
       "  '블랙',\n",
       "  '##펄',\n",
       "  '(',\n",
       "  'B',\n",
       "  '##l',\n",
       "  '##ac',\n",
       "  '##k',\n",
       "  'P',\n",
       "  '##e',\n",
       "  '##ar',\n",
       "  '##l',\n",
       "  ')',\n",
       "  \"'\",\n",
       "  '로',\n",
       "  '공식',\n",
       "  '브',\n",
       "  '##랜',\n",
       "  '##딩',\n",
       "  '##하고',\n",
       "  ',',\n",
       "  '하',\n",
       "  '##반기',\n",
       "  '중',\n",
       "  '픽',\n",
       "  '##셀',\n",
       "  '크',\n",
       "  '##기로',\n",
       "  '48',\n",
       "  '##00만',\n",
       "  '##화',\n",
       "  '##소를',\n",
       "  '구',\n",
       "  '##현',\n",
       "  '##한',\n",
       "  '제품',\n",
       "  '##도',\n",
       "  '선보',\n",
       "  '##인다',\n",
       "  '##는',\n",
       "  '계획이다',\n",
       "  '.'],\n",
       " ['SK',\n",
       "  '##하이',\n",
       "  '##닉',\n",
       "  '##스',\n",
       "  '##시스템',\n",
       "  '##I',\n",
       "  '##C',\n",
       "  '##는',\n",
       "  '중국',\n",
       "  '장',\n",
       "  '##쑤',\n",
       "  '##성',\n",
       "  '우',\n",
       "  '##시에',\n",
       "  '##서',\n",
       "  '합작',\n",
       "  '##법인',\n",
       "  '##을',\n",
       "  '설립',\n",
       "  '##해',\n",
       "  '파',\n",
       "  '##운드',\n",
       "  '##리',\n",
       "  '공장',\n",
       "  '##을',\n",
       "  '건설',\n",
       "  '##하고',\n",
       "  '있다',\n",
       "  '.'],\n",
       " ['올해',\n",
       "  '2',\n",
       "  '##분기',\n",
       "  '내',\n",
       "  '준',\n",
       "  '##공',\n",
       "  '##되면',\n",
       "  '연말',\n",
       "  '양산',\n",
       "  '##이',\n",
       "  '목표',\n",
       "  '##다',\n",
       "  '.'],\n",
       " ['SK',\n",
       "  '##하이',\n",
       "  '##닉',\n",
       "  '##스는',\n",
       "  '이날',\n",
       "  '매',\n",
       "  '##그',\n",
       "  '##나',\n",
       "  '##칩',\n",
       "  '##반도',\n",
       "  '##체의',\n",
       "  '파',\n",
       "  '##운드',\n",
       "  '##리',\n",
       "  '(',\n",
       "  '반도체',\n",
       "  '위',\n",
       "  '##탁',\n",
       "  '##생산',\n",
       "  ')',\n",
       "  '부문',\n",
       "  '##도',\n",
       "  '인수',\n",
       "  '##했다',\n",
       "  '.'],\n",
       " ['박', '##세', '##준', '기자', '세상을', '보는', '눈', ',', '세계', '##일보']]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = 0\n",
    "for sen_ids in input_ids:\n",
    "    now_len = len(sen_ids)\n",
    "    if now_len > max_len:\n",
    "        max_len = now_len\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT의 단어 집합을 vocabulary.txt에 저장\n",
    "with open('./finbert_vocabulary.txt', 'w') as f:\n",
    "    for token in tokenizer.vocab.keys():\n",
    "        f.write(token + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'positive', 'score': 0.818943202495575}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier  = pipeline('sentiment-analysis', model='snunlp/KR-FinBert-SC')\n",
    "result = classifier(text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"D램, 낸드플래시 매출은 각각 37%, 31% ↓ / 中 파운드리 공장 2분기 2020년 말 양산 \\nSK하이닉스 이천 사업장. 연합뉴스 SK하이닉스의 지난해 매출액이 전년 대비 33% 감소했지만, 비메모리 반도체 매출은 50%가량 증가한 것으로 나타났다. 31일 SK하이닉스의 사업보고서에 따르면, 2019년 D램 매출은 20조3000억원으로 전년과 비교해 37% 감소했고, 낸드플래시 매출은 5조1000억원으로 31% 줄어든 것으로 집계됐다. 반면 비메모리 사업을 포함한 기타 항목 매출은 2018년 6500억원에서 지난해 1조6000억원으로 2배 이상 증가했다. 지난해 기타 매출 가운데는 SK하이닉스가 2018년 12월 지분 100%를 인수한 사회적기업 행복나래 등 자회사 매출 약 7000억원이 포함됐다. 나머지 매출 약 8000억원은 이미지센서 부문과 파운드리 자회사 SK하이닉스시스템IC 등 비메모리 반도체 사업으로, 2018년(5500억여원) 대비 성장한 것으로 파악된다. 이에 따라 D램 부문 매출 비중은 2018년 80%에서 지난해 75%로 줄어들었고, 기타 항목 비중은 같은 기간 2%에서 6%로 확대됐다. SK하이닉스가 주력하는 분야는 비메모리 사업 중에서도 모바일, 노트북용 이미지센서 시장이다. 지난해 일본에 차세대 CIS(CMOS 이미지센서) 연구개발센터를 여는 등 시장 점유율 확대를 위한 제품 개발에 주력하고 있다. 올해는 모든 CIS 제품을 '블랙펄(Black Pearl)'로 공식 브랜딩하고, 하반기 중 픽셀 크기로 4800만화소를 구현한 제품도 선보인다는 계획이다. SK하이닉스시스템IC는 중국 장쑤성 우시에서 합작법인을 설립해 파운드리 공장을 건설하고 있다. 올해 2분기 내 준공되면 연말 양산이 목표다. SK하이닉스는 이날 매그나칩반도체의 파운드리(반도체 위탁생산) 부문도 인수했다. 박세준 기자 세상을 보는 눈, 세계일보\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function pipeline in module transformers.pipelines:\n",
      "\n",
      "pipeline(task: str = None, model: Optional = None, config: Union[str, transformers.configuration_utils.PretrainedConfig, NoneType] = None, tokenizer: Union[str, transformers.tokenization_utils.PreTrainedTokenizer, transformers.tokenization_utils_fast.PreTrainedTokenizerFast, NoneType] = None, feature_extractor: Union[str, ForwardRef('SequenceFeatureExtractor'), NoneType] = None, framework: Optional[str] = None, revision: Optional[str] = None, use_fast: bool = True, use_auth_token: Union[bool, str, NoneType] = None, device: Union[int, str, ForwardRef('torch.device'), NoneType] = None, device_map=None, torch_dtype=None, trust_remote_code: Optional[bool] = None, model_kwargs: Dict[str, Any] = None, pipeline_class: Optional[Any] = None, **kwargs) -> transformers.pipelines.base.Pipeline\n",
      "    Utility factory method to build a [`Pipeline`].\n",
      "    \n",
      "    Pipelines are made of:\n",
      "    \n",
      "        - A [tokenizer](tokenizer) in charge of mapping raw textual input to token.\n",
      "        - A [model](model) to make predictions from the inputs.\n",
      "        - Some (optional) post processing for enhancing model's output.\n",
      "    \n",
      "    Args:\n",
      "        task (`str`):\n",
      "            The task defining which pipeline will be returned. Currently accepted tasks are:\n",
      "    \n",
      "            - `\"audio-classification\"`: will return a [`AudioClassificationPipeline`].\n",
      "            - `\"automatic-speech-recognition\"`: will return a [`AutomaticSpeechRecognitionPipeline`].\n",
      "            - `\"conversational\"`: will return a [`ConversationalPipeline`].\n",
      "            - `\"feature-extraction\"`: will return a [`FeatureExtractionPipeline`].\n",
      "            - `\"fill-mask\"`: will return a [`FillMaskPipeline`]:.\n",
      "            - `\"image-classification\"`: will return a [`ImageClassificationPipeline`].\n",
      "            - `\"question-answering\"`: will return a [`QuestionAnsweringPipeline`].\n",
      "            - `\"table-question-answering\"`: will return a [`TableQuestionAnsweringPipeline`].\n",
      "            - `\"text2text-generation\"`: will return a [`Text2TextGenerationPipeline`].\n",
      "            - `\"text-classification\"` (alias `\"sentiment-analysis\"` available): will return a\n",
      "              [`TextClassificationPipeline`].\n",
      "            - `\"text-generation\"`: will return a [`TextGenerationPipeline`]:.\n",
      "            - `\"token-classification\"` (alias `\"ner\"` available): will return a [`TokenClassificationPipeline`].\n",
      "            - `\"translation\"`: will return a [`TranslationPipeline`].\n",
      "            - `\"translation_xx_to_yy\"`: will return a [`TranslationPipeline`].\n",
      "            - `\"summarization\"`: will return a [`SummarizationPipeline`].\n",
      "            - `\"zero-shot-classification\"`: will return a [`ZeroShotClassificationPipeline`].\n",
      "    \n",
      "        model (`str` or [`PreTrainedModel`] or [`TFPreTrainedModel`], *optional*):\n",
      "            The model that will be used by the pipeline to make predictions. This can be a model identifier or an\n",
      "            actual instance of a pretrained model inheriting from [`PreTrainedModel`] (for PyTorch) or\n",
      "            [`TFPreTrainedModel`] (for TensorFlow).\n",
      "    \n",
      "            If not provided, the default for the `task` will be loaded.\n",
      "        config (`str` or [`PretrainedConfig`], *optional*):\n",
      "            The configuration that will be used by the pipeline to instantiate the model. This can be a model\n",
      "            identifier or an actual pretrained model configuration inheriting from [`PretrainedConfig`].\n",
      "    \n",
      "            If not provided, the default configuration file for the requested model will be used. That means that if\n",
      "            `model` is given, its default configuration will be used. However, if `model` is not supplied, this\n",
      "            `task`'s default model's config is used instead.\n",
      "        tokenizer (`str` or [`PreTrainedTokenizer`], *optional*):\n",
      "            The tokenizer that will be used by the pipeline to encode data for the model. This can be a model\n",
      "            identifier or an actual pretrained tokenizer inheriting from [`PreTrainedTokenizer`].\n",
      "    \n",
      "            If not provided, the default tokenizer for the given `model` will be loaded (if it is a string). If `model`\n",
      "            is not specified or not a string, then the default tokenizer for `config` is loaded (if it is a string).\n",
      "            However, if `config` is also not given or not a string, then the default tokenizer for the given `task`\n",
      "            will be loaded.\n",
      "        feature_extractor (`str` or [`PreTrainedFeatureExtractor`], *optional*):\n",
      "            The feature extractor that will be used by the pipeline to encode data for the model. This can be a model\n",
      "            identifier or an actual pretrained feature extractor inheriting from [`PreTrainedFeatureExtractor`].\n",
      "    \n",
      "            Feature extractors are used for non-NLP models, such as Speech or Vision models as well as multi-modal\n",
      "            models. Multi-modal models will also require a tokenizer to be passed.\n",
      "    \n",
      "            If not provided, the default feature extractor for the given `model` will be loaded (if it is a string). If\n",
      "            `model` is not specified or not a string, then the default feature extractor for `config` is loaded (if it\n",
      "            is a string). However, if `config` is also not given or not a string, then the default feature extractor\n",
      "            for the given `task` will be loaded.\n",
      "        framework (`str`, *optional*):\n",
      "            The framework to use, either `\"pt\"` for PyTorch or `\"tf\"` for TensorFlow. The specified framework must be\n",
      "            installed.\n",
      "    \n",
      "            If no framework is specified, will default to the one currently installed. If no framework is specified and\n",
      "            both frameworks are installed, will default to the framework of the `model`, or to PyTorch if no model is\n",
      "            provided.\n",
      "        revision (`str`, *optional*, defaults to `\"main\"`):\n",
      "            When passing a task name or a string model identifier: The specific model version to use. It can be a\n",
      "            branch name, a tag name, or a commit id, since we use a git-based system for storing models and other\n",
      "            artifacts on huggingface.co, so `revision` can be any identifier allowed by git.\n",
      "        use_fast (`bool`, *optional*, defaults to `True`):\n",
      "            Whether or not to use a Fast tokenizer if possible (a [`PreTrainedTokenizerFast`]).\n",
      "        use_auth_token (`str` or *bool*, *optional*):\n",
      "            The token to use as HTTP bearer authorization for remote files. If `True`, will use the token generated\n",
      "            when running `huggingface-cli login` (stored in `~/.huggingface`).\n",
      "        device (`int` or `str` or `torch.device`):\n",
      "            Defines the device (*e.g.*, `\"cpu\"`, `\"cuda:1\"`, `\"mps\"`, or a GPU ordinal rank like `1`) on which this\n",
      "            pipeline will be allocated.\n",
      "        device_map (`str` or `Dict[str, Union[int, str, torch.device]`, *optional*):\n",
      "            Sent directly as `model_kwargs` (just a simpler shortcut). When `accelerate` library is present, set\n",
      "            `device_map=\"auto\"` to compute the most optimized `device_map` automatically. [More\n",
      "            information](https://huggingface.co/docs/accelerate/main/en/big_modeling#accelerate.cpu_offload)\n",
      "    \n",
      "            <Tip warning={true}>\n",
      "    \n",
      "            Do not use `device_map` AND `device` at the same time as they will conflict\n",
      "    \n",
      "            </Tip>\n",
      "    \n",
      "        torch_dtype (`str` or `torch.dtype`, *optional*):\n",
      "            Sent directly as `model_kwargs` (just a simpler shortcut) to use the available precision for this model\n",
      "            (`torch.float16`, `torch.bfloat16`, ... or `\"auto\"`).\n",
      "        trust_remote_code (`bool`, *optional*, defaults to `False`):\n",
      "            Whether or not to allow for custom code defined on the Hub in their own modeling, configuration,\n",
      "            tokenization or even pipeline files. This option should only be set to `True` for repositories you trust\n",
      "            and in which you have read the code, as it will execute code present on the Hub on your local machine.\n",
      "        model_kwargs:\n",
      "            Additional dictionary of keyword arguments passed along to the model's `from_pretrained(...,\n",
      "            **model_kwargs)` function.\n",
      "        kwargs:\n",
      "            Additional keyword arguments passed along to the specific pipeline init (see the documentation for the\n",
      "            corresponding pipeline class for possible values).\n",
      "    \n",
      "    Returns:\n",
      "        [`Pipeline`]: A suitable pipeline for the task.\n",
      "    \n",
      "    Examples:\n",
      "    \n",
      "    ```python\n",
      "    >>> from transformers import pipeline, AutoModelForTokenClassification, AutoTokenizer\n",
      "    \n",
      "    >>> # Sentiment analysis pipeline\n",
      "    >>> pipeline(\"sentiment-analysis\")\n",
      "    \n",
      "    >>> # Question answering pipeline, specifying the checkpoint identifier\n",
      "    >>> pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\", tokenizer=\"bert-base-cased\")\n",
      "    \n",
      "    >>> # Named entity recognition pipeline, passing in a specific model and tokenizer\n",
      "    >>> model = AutoModelForTokenClassification.from_pretrained(\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
      "    >>> tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
      "    >>> pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
      "    ```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2304: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 특수문자 하나하나가 토큰이라서 특수문자 제거하고 해야함\n",
    "\n",
    "encoded_dict = tokenizer.encode_plus(\n",
    "    text=text, \n",
    "    add_special_tokens=True, # cls, sep 등\n",
    "    max_length=64, # 최대 길이 설정\n",
    "    pad_to_max_length=True, # 패딩 여부\n",
    "    return_attention_mask=True, # 패딩한 부분은 0으로 처리하는 마스크\n",
    "    truncation=True\n",
    ")# 기본적으로 뒤를 자르게 설정됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dict['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dict['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dict['token_type_ids']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0426"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>keyword</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>writed_at</th>\n",
       "      <th>writer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D램, 낸드플래시 매출은 각각 37%, 31% ↓ / 中 파운드리 공장 2분기 20...</td>\n",
       "      <td>하이닉스</td>\n",
       "      <td>SK하이닉스, 2019년 비메모리 매출 50% ↑</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/022/000...</td>\n",
       "      <td>2020-04-01 03:04:05</td>\n",
       "      <td>박세준</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[이데일리 최정희 기자] 삼성전자(005930), SK하이닉스(000660) 주가가...</td>\n",
       "      <td>하이닉스</td>\n",
       "      <td>[특징주]1분기 실적 호조에 삼성전자·SK하이닉스 강세</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/018/000...</td>\n",
       "      <td>2020-04-07 09:16:04</td>\n",
       "      <td>최정희</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SK하이닉스[연합뉴스TV 제공] (서울=연합뉴스) 김기훈 기자 = 유진투자증권은 1...</td>\n",
       "      <td>하이닉스</td>\n",
       "      <td>유진투자 \"하반기 메모리 가격 하락 전망…SK하이닉스 목표가↓\"</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/001/001...</td>\n",
       "      <td>2020-04-14 08:39:00</td>\n",
       "      <td>김기훈</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[머니투데이 김태현 기자] 삼성증권은 SK하이닉스에 대해 환율효과와 낸드마진 등으로...</td>\n",
       "      <td>하이닉스</td>\n",
       "      <td>SK하이닉스, 낸드마진 개선…1Q 호실적 기대-삼성</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/008/000...</td>\n",
       "      <td>2020-04-20 08:35:37</td>\n",
       "      <td>김태현</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SK하이닉스가 메모리 반도체 가격 상승에 힘입어 올 1분기 영업이익 8000억원을 ...</td>\n",
       "      <td>하이닉스</td>\n",
       "      <td>SK하이닉스 코로나에도 '어닝 서프라이즈'...1분기 영업이익 8003억원</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/366/000...</td>\n",
       "      <td>2020-04-23 08:37:21</td>\n",
       "      <td>윤민혁</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content keyword  \\\n",
       "0  D램, 낸드플래시 매출은 각각 37%, 31% ↓ / 中 파운드리 공장 2분기 20...    하이닉스   \n",
       "1  [이데일리 최정희 기자] 삼성전자(005930), SK하이닉스(000660) 주가가...    하이닉스   \n",
       "2  SK하이닉스[연합뉴스TV 제공] (서울=연합뉴스) 김기훈 기자 = 유진투자증권은 1...    하이닉스   \n",
       "3  [머니투데이 김태현 기자] 삼성증권은 SK하이닉스에 대해 환율효과와 낸드마진 등으로...    하이닉스   \n",
       "4  SK하이닉스가 메모리 반도체 가격 상승에 힘입어 올 1분기 영업이익 8000억원을 ...    하이닉스   \n",
       "\n",
       "                                       title  \\\n",
       "0                SK하이닉스, 2019년 비메모리 매출 50% ↑   \n",
       "1             [특징주]1분기 실적 호조에 삼성전자·SK하이닉스 강세   \n",
       "2        유진투자 \"하반기 메모리 가격 하락 전망…SK하이닉스 목표가↓\"   \n",
       "3               SK하이닉스, 낸드마진 개선…1Q 호실적 기대-삼성   \n",
       "4  SK하이닉스 코로나에도 '어닝 서프라이즈'...1분기 영업이익 8003억원   \n",
       "\n",
       "                                                 url            writed_at  \\\n",
       "0  https://n.news.naver.com/mnews/article/022/000...  2020-04-01 03:04:05   \n",
       "1  https://n.news.naver.com/mnews/article/018/000...  2020-04-07 09:16:04   \n",
       "2  https://n.news.naver.com/mnews/article/001/001...  2020-04-14 08:39:00   \n",
       "3  https://n.news.naver.com/mnews/article/008/000...  2020-04-20 08:35:37   \n",
       "4  https://n.news.naver.com/mnews/article/366/000...  2020-04-23 08:37:21   \n",
       "\n",
       "  writer  \n",
       "0    박세준  \n",
       "1    최정희  \n",
       "2    김기훈  \n",
       "3    김태현  \n",
       "4    윤민혁  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./data_in_title.csv', dtype=object)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6734 entries, 0 to 6733\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   content    6734 non-null   object\n",
      " 1   keyword    6734 non-null   object\n",
      " 2   title      6734 non-null   object\n",
      " 3   url        6734 non-null   object\n",
      " 4   writed_at  6734 non-null   object\n",
      " 5   writer     6612 non-null   object\n",
      "dtypes: object(6)\n",
      "memory usage: 315.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\", do_lower_case=False)\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=2)\n",
    "\n",
    "#https://github.com/huggingface/transformers/issues/5421"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"snunlp/KR-FinBert-SC\")\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\"snunlp/KR-FinBert-SC\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 368page~ 텐서플로 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "\n",
    "def bert_tokenizer(sent, MAX_LEN, pt=None):\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "        text=sent,\n",
    "        add_special_tokens = True,\n",
    "        max_length = MAX_LEN,\n",
    "        padding = True,\n",
    "        return_attention_mask = True,\n",
    "        truncation = True,\n",
    "        return_tensors = pt\n",
    "    )\n",
    "\n",
    "    input_id = encoded_dict['input_ids']\n",
    "    attention_mask = encoded_dict['attention_mask']\n",
    "    token_type_id = encoded_dict['token_type_ids']\n",
    "\n",
    "    return input_id, attention_mask, token_type_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = data.content.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[   101,    141, 118857,    117,   8997,  15001, 119412,  37388,  14040,\n",
       "            9258,  52363,  10892,  63042,  11204,    110,    117,  10413,    110,\n",
       "            1792,    120,   2104,   9901,  98511,  12692,   8896,  13890,    123,\n",
       "           37712,  12310,  23607,  10954,   9251,   9543,  21386,  21275,  35506,\n",
       "           10739, 118766,  12605,   9638,  38631,   9405,  26784,  13890,    119,\n",
       "           94224,  21275,  35506,  10739, 118766,  49319,   9706,  33305,  14523,\n",
       "            9258,  52363, 119122,  10739,   9665,  10954,   9069,  29455,  11000,\n",
       "             102]]),\n",
       " tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n",
       " tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokenizer(text, 64, 'pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([101, 141, 118857, 117, 8997, 15001, 119412, 37388, 14040, 9258, 52363, 10892, 63042, 11204, 110, 117, 10413, 110, 1792, 120, 2104, 9901, 98511, 12692, 8896, 13890, 123, 37712, 12310, 23607, 10954, 9251, 9543, 21386, 21275, 35506, 10739, 118766, 12605, 9638, 38631, 9405, 26784, 13890, 119, 94224, 21275, 35506, 10739, 118766, 49319, 9706, 33305, 14523, 9258, 52363, 119122, 10739, 9665, 10954, 9069, 29455, 11000, 102], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "print(bert_tokenizer(text, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[UNK]', '[SEP]', '[PAD]', '[CLS]', '[MASK]'] \n",
      " [100, 102, 0, 101, 103]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.all_special_tokens,\"\\n\",tokenizer.all_special_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.content.values[:3]\n",
    "train_labels = np.array([1,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = []\n",
    "attention_masks = []\n",
    "token_type_ids = []\n",
    "train_data_labels = []\n",
    "\n",
    "def clean_text(sent):\n",
    "    sent_clean = re.sub(\"[^가-힣a-zA-Z0-9 ]\", \" \", sent)\n",
    "    return sent_clean\n",
    "\n",
    "for train_sent, train_label in zip(train, train_labels):\n",
    "    try:\n",
    "        input_id, attention_mask, token_type_id = bert_tokenizer(clean_text(train_sent), 128)\n",
    "\n",
    "        input_ids.append(input_id)\n",
    "        attention_masks.append(attention_mask)\n",
    "        token_type_ids.append(token_type_id)\n",
    "        train_data_labels.append(train_label)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(train_sent)\n",
    "\n",
    "input_ids = np.array(input_ids, dtype=int)\n",
    "attention_masks = np.array(attention_masks, dtype=int)\n",
    "token_type_ids = np.array(token_type_ids, dtype=int)\n",
    "inputs = (input_ids, attention_masks, token_type_ids)\n",
    "\n",
    "labels = np.array(train_data_labels, dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] D램 낸드플래시 매출은 각각 37 31 파운드리 공장 2분기 2020년 말 양산 SK하이닉스 이천 사업장 연합뉴스 SK하이닉스의 지난해 매출액이 전년 대비 33 감소했지만 비메모리 반도체 매출은 50 가량 증가한 것으로 나타났다 31일 SK하이닉스의 사업보고서에 따르면 2019년 D램 매출은 20조3000억원으로 전년과 비교해 37 감소했고 낸드플래시 매출은 5조1000억 [SEP]'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "# import tensorflow_models as tfm\n",
    "# import tensorflow_hub as hub\n",
    "# import tensorflow_datasets as tfds\n",
    "# tfds.disable_progress_bar()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf-models-official\n",
      "  Using cached tf_models_official-2.12.0-py2.py3-none-any.whl (2.6 MB)\n",
      "Collecting immutabledict\n",
      "  Using cached immutabledict-2.2.4-py3-none-any.whl (4.1 kB)\n",
      "Requirement already satisfied: pyyaml<6.0,>=5.1 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tf-models-official) (5.4.1)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tf-models-official) (0.1.98)\n",
      "Requirement already satisfied: seqeval in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tf-models-official) (1.2.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tf-models-official) (3.7.0)\n",
      "Requirement already satisfied: tensorflow-addons in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tf-models-official) (0.20.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tf-models-official) (1.23.5)\n",
      "Requirement already satisfied: psutil>=5.4.3 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tf-models-official) (5.9.0)\n",
      "Requirement already satisfied: tensorflow-model-optimization>=0.4.1 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tf-models-official) (0.7.4)\n",
      "Requirement already satisfied: pandas>=0.22.0 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tf-models-official) (1.5.3)\n",
      "Collecting tf-models-official\n",
      "  Using cached tf_models_official-2.11.5-py2.py3-none-any.whl (2.4 MB)\n",
      "Collecting tensorflow~=2.11.0\n",
      "  Using cached tensorflow-2.11.1-cp310-cp310-win_amd64.whl (1.9 kB)\n",
      "Collecting tf-models-official\n",
      "  Using cached tf_models_official-2.11.4-py2.py3-none-any.whl (2.4 MB)\n",
      "  Using cached tf_models_official-2.11.3-py2.py3-none-any.whl (2.3 MB)\n",
      "  Using cached tf_models_official-2.11.2-py2.py3-none-any.whl (2.3 MB)\n",
      "  Using cached tf_models_official-2.11.0-py2.py3-none-any.whl (2.3 MB)\n",
      "  Using cached tf_models_official-2.10.1-py2.py3-none-any.whl (2.2 MB)\n",
      "Collecting tensorflow-text~=2.10.0\n",
      "  Using cached tensorflow_text-2.10.0-cp310-cp310-win_amd64.whl (5.0 MB)\n",
      "Requirement already satisfied: tf-slim>=1.1.0 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tf-models-official) (1.1.0)\n",
      "Requirement already satisfied: Cython in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tf-models-official) (0.29.34)\n",
      "Requirement already satisfied: py-cpuinfo>=3.3.0 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tf-models-official) (9.0.0)\n",
      "Requirement already satisfied: gin-config in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tf-models-official) (0.5.0)\n",
      "Requirement already satisfied: pycocotools in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tf-models-official) (2.0.6)\n",
      "Requirement already satisfied: oauth2client in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tf-models-official) (4.1.3)\n",
      "Requirement already satisfied: opencv-python-headless in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tf-models-official) (4.7.0.72)\n",
      "Requirement already satisfied: six in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tf-models-official) (1.16.0)\n",
      "Collecting tensorflow~=2.10.0\n",
      "  Using cached tensorflow-2.10.1-cp310-cp310-win_amd64.whl (455.9 MB)\n",
      "Requirement already satisfied: tensorflow-datasets in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tf-models-official) (4.9.0)\n",
      "Requirement already satisfied: google-api-python-client>=1.6.7 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tf-models-official) (2.86.0)\n",
      "Requirement already satisfied: kaggle>=1.3.9 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tf-models-official) (1.5.13)\n",
      "Requirement already satisfied: Pillow in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tf-models-official) (9.4.0)\n",
      "Collecting sacrebleu==2.2.0\n",
      "  Using cached sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n",
      "Requirement already satisfied: tensorflow-hub>=0.6.0 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tf-models-official) (0.13.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tf-models-official) (1.10.1)\n",
      "Requirement already satisfied: lxml in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from sacrebleu==2.2.0->tf-models-official) (4.9.2)\n",
      "Requirement already satisfied: portalocker in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from sacrebleu==2.2.0->tf-models-official) (2.7.0)\n",
      "Requirement already satisfied: regex in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from sacrebleu==2.2.0->tf-models-official) (2022.10.31)\n",
      "Requirement already satisfied: colorama in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from sacrebleu==2.2.0->tf-models-official) (0.4.6)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from sacrebleu==2.2.0->tf-models-official) (0.9.0)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.15.0 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from google-api-python-client>=1.6.7->tf-models-official) (0.22.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from google-api-python-client>=1.6.7->tf-models-official) (4.1.1)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from google-api-python-client>=1.6.7->tf-models-official) (2.11.0)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.1.0 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from google-api-python-client>=1.6.7->tf-models-official) (0.1.0)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from google-api-python-client>=1.6.7->tf-models-official) (2.17.3)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from kaggle>=1.3.9->tf-models-official) (8.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from kaggle>=1.3.9->tf-models-official) (2.28.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from kaggle>=1.3.9->tf-models-official) (4.65.0)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from kaggle>=1.3.9->tf-models-official) (2.8.2)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from kaggle>=1.3.9->tf-models-official) (1.26.15)\n",
      "Requirement already satisfied: certifi in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from kaggle>=1.3.9->tf-models-official) (2022.12.7)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from pandas>=0.22.0->tf-models-official) (2023.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow~=2.10.0->tf-models-official) (1.3.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow~=2.10.0->tf-models-official) (0.2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow~=2.10.0->tf-models-official) (1.6.3)\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Using cached protobuf-3.19.6-cp310-cp310-win_amd64.whl (895 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow~=2.10.0->tf-models-official) (23.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow~=2.10.0->tf-models-official) (2.2.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow~=2.10.0->tf-models-official) (1.1.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow~=2.10.0->tf-models-official) (3.3.0)\n",
      "Collecting keras<2.11,>=2.10.0\n",
      "  Using cached keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow~=2.10.0->tf-models-official) (65.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow~=2.10.0->tf-models-official) (23.3.3)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow~=2.10.0->tf-models-official) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow~=2.10.0->tf-models-official) (2.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow~=2.10.0->tf-models-official) (4.5.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow~=2.10.0->tf-models-official) (3.7.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow~=2.10.0->tf-models-official) (0.31.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow~=2.10.0->tf-models-official) (0.4.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow~=2.10.0->tf-models-official) (1.42.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow~=2.10.0->tf-models-official) (16.0.0)\n",
      "Collecting tensorboard<2.11,>=2.10\n",
      "  Using cached tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
      "Requirement already satisfied: dm-tree~=0.1.1 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official) (0.1.8)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from matplotlib->tf-models-official) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from matplotlib->tf-models-official) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from matplotlib->tf-models-official) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from matplotlib->tf-models-official) (4.38.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from matplotlib->tf-models-official) (1.0.7)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from oauth2client->tf-models-official) (0.4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from oauth2client->tf-models-official) (0.2.8)\n",
      "Requirement already satisfied: rsa>=3.1.4 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from oauth2client->tf-models-official) (4.9)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from seqeval->tf-models-official) (1.2.1)\n",
      "Requirement already satisfied: typeguard<3.0.0,>=2.7 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow-addons->tf-models-official) (2.13.3)\n",
      "Requirement already satisfied: etils[enp,epath]>=0.9.0 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow-datasets->tf-models-official) (1.2.0)\n",
      "Requirement already satisfied: promise in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow-datasets->tf-models-official) (2.3)\n",
      "Requirement already satisfied: tensorflow-metadata in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow-datasets->tf-models-official) (1.13.0)\n",
      "Requirement already satisfied: click in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow-datasets->tf-models-official) (8.1.3)\n",
      "Requirement already satisfied: array-record in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow-datasets->tf-models-official) (0.2.0)\n",
      "Requirement already satisfied: toml in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow-datasets->tf-models-official) (0.10.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from astunparse>=1.6.0->tensorflow~=2.10.0->tf-models-official) (0.37.1)\n",
      "Requirement already satisfied: zipp in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->tf-models-official) (3.15.0)\n",
      "Requirement already satisfied: importlib_resources in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->tf-models-official) (5.12.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official) (1.59.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official) (4.2.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from requests->kaggle>=1.3.9->tf-models-official) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from requests->kaggle>=1.3.9->tf-models-official) (3.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official) (1.2.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official) (0.4.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official) (2.2.3)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official) (3.4.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: 'c:\\\\users\\\\tlrks\\\\anaconda3\\\\envs\\\\study\\\\lib\\\\site-packages\\\\tensorflow_estimator-2.10.0.dist-info\\\\METADATA'\n",
      "\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tf-models-official"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-datasets in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (4.9.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow-datasets) (4.65.0)\n",
      "Requirement already satisfied: promise in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow-datasets) (2.3)\n",
      "Requirement already satisfied: tensorflow-metadata in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow-datasets) (1.13.0)\n",
      "Requirement already satisfied: toml in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow-datasets) (0.10.2)\n",
      "Requirement already satisfied: termcolor in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow-datasets) (2.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow-datasets) (1.23.5)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow-datasets) (2.28.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow-datasets) (5.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow-datasets) (1.14.1)\n",
      "Requirement already satisfied: absl-py in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow-datasets) (1.3.0)\n",
      "Requirement already satisfied: etils[enp,epath]>=0.9.0 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow-datasets) (1.2.0)\n",
      "Requirement already satisfied: array-record in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow-datasets) (0.2.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow-datasets) (3.20.3)\n",
      "Requirement already satisfied: dm-tree in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow-datasets) (0.1.8)\n",
      "Requirement already satisfied: click in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow-datasets) (8.1.3)\n",
      "Requirement already satisfied: zipp in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets) (3.15.0)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets) (4.5.0)\n",
      "Requirement already satisfied: importlib_resources in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets) (5.12.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets) (1.26.15)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets) (3.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets) (2022.12.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from click->tensorflow-datasets) (0.4.6)\n",
      "Requirement already satisfied: six in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from promise->tensorflow-datasets) (1.16.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow-metadata->tensorflow-datasets) (1.59.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Error parsing requirements for tensorflow-estimator: [Errno 2] No such file or directory: 'c:\\\\users\\\\tlrks\\\\anaconda3\\\\envs\\\\study\\\\lib\\\\site-packages\\\\tensorflow_estimator-2.10.0.dist-info\\\\METADATA'\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_hub\n",
      "  Using cached tensorflow_hub-0.13.0-py2.py3-none-any.whl (100 kB)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow_hub) (1.23.5)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow_hub) (4.22.1)\n",
      "Installing collected packages: tensorflow_hub\n",
      "Successfully installed tensorflow_hub-0.13.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade tensorflow_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-text\n",
      "  Using cached tensorflow_text-2.10.0-cp310-cp310-win_amd64.whl (5.0 MB)\n",
      "Collecting tensorflow<2.11,>=2.10.0\n",
      "  Downloading tensorflow-2.10.1-cp310-cp310-win_amd64.whl (455.9 MB)\n",
      "     ---------------------------------------- 0.0/455.9 MB ? eta -:--:--\n",
      "     --------------------------------------- 0.4/455.9 MB 11.6 MB/s eta 0:00:40\n",
      "     --------------------------------------- 0.9/455.9 MB 11.6 MB/s eta 0:00:40\n",
      "     --------------------------------------- 1.4/455.9 MB 11.4 MB/s eta 0:00:40\n",
      "     --------------------------------------- 1.8/455.9 MB 10.6 MB/s eta 0:00:43\n",
      "     --------------------------------------- 2.4/455.9 MB 10.8 MB/s eta 0:00:42\n",
      "     --------------------------------------- 2.9/455.9 MB 10.9 MB/s eta 0:00:42\n",
      "     --------------------------------------- 3.4/455.9 MB 11.5 MB/s eta 0:00:40\n",
      "     --------------------------------------- 4.0/455.9 MB 11.5 MB/s eta 0:00:40\n",
      "     --------------------------------------- 4.5/455.9 MB 11.4 MB/s eta 0:00:40\n",
      "     --------------------------------------- 5.0/455.9 MB 11.5 MB/s eta 0:00:40\n",
      "     --------------------------------------- 5.6/455.9 MB 11.5 MB/s eta 0:00:40\n",
      "      -------------------------------------- 6.1/455.9 MB 11.4 MB/s eta 0:00:40\n",
      "      -------------------------------------- 6.6/455.9 MB 11.4 MB/s eta 0:00:40\n",
      "      -------------------------------------- 7.1/455.9 MB 11.4 MB/s eta 0:00:40\n",
      "      -------------------------------------- 7.7/455.9 MB 11.7 MB/s eta 0:00:39\n",
      "      -------------------------------------- 8.2/455.9 MB 11.7 MB/s eta 0:00:39\n",
      "      -------------------------------------- 8.7/455.9 MB 11.6 MB/s eta 0:00:39\n",
      "      -------------------------------------- 9.3/455.9 MB 11.6 MB/s eta 0:00:39\n",
      "      -------------------------------------- 9.8/455.9 MB 11.6 MB/s eta 0:00:39\n",
      "      ------------------------------------- 10.3/455.9 MB 11.7 MB/s eta 0:00:39\n",
      "      ------------------------------------- 10.9/455.9 MB 11.7 MB/s eta 0:00:39\n",
      "      ------------------------------------- 11.4/455.9 MB 11.5 MB/s eta 0:00:39\n",
      "      ------------------------------------- 11.9/455.9 MB 11.7 MB/s eta 0:00:38\n",
      "     - ------------------------------------ 12.5/455.9 MB 11.9 MB/s eta 0:00:38\n",
      "     - ------------------------------------ 13.0/455.9 MB 11.9 MB/s eta 0:00:38\n",
      "     - ------------------------------------ 13.5/455.9 MB 11.9 MB/s eta 0:00:38\n",
      "     - ------------------------------------ 14.1/455.9 MB 11.9 MB/s eta 0:00:38\n",
      "     - ------------------------------------ 14.6/455.9 MB 11.9 MB/s eta 0:00:38\n",
      "     - ------------------------------------ 15.1/455.9 MB 11.7 MB/s eta 0:00:38\n",
      "     - ------------------------------------ 15.7/455.9 MB 11.7 MB/s eta 0:00:38\n",
      "     - ------------------------------------ 16.1/455.9 MB 11.7 MB/s eta 0:00:38\n",
      "     - ------------------------------------ 16.7/455.9 MB 11.7 MB/s eta 0:00:38\n",
      "     - ------------------------------------ 17.3/455.9 MB 11.9 MB/s eta 0:00:37\n",
      "     - ------------------------------------ 17.8/455.9 MB 11.9 MB/s eta 0:00:37\n",
      "     - ------------------------------------ 18.3/455.9 MB 11.9 MB/s eta 0:00:37\n",
      "     - ------------------------------------ 18.8/455.9 MB 11.9 MB/s eta 0:00:37\n",
      "     - ------------------------------------ 19.4/455.9 MB 11.7 MB/s eta 0:00:38\n",
      "     - ------------------------------------ 19.9/455.9 MB 11.7 MB/s eta 0:00:38\n",
      "     - ------------------------------------ 20.4/455.9 MB 11.7 MB/s eta 0:00:38\n",
      "     - ------------------------------------ 20.9/455.9 MB 11.7 MB/s eta 0:00:38\n",
      "     - ------------------------------------ 21.5/455.9 MB 11.9 MB/s eta 0:00:37\n",
      "     - ------------------------------------ 22.0/455.9 MB 11.9 MB/s eta 0:00:37\n",
      "     - ------------------------------------ 22.0/455.9 MB 11.9 MB/s eta 0:00:37\n",
      "     - ------------------------------------ 22.0/455.9 MB 11.9 MB/s eta 0:00:37\n",
      "     - ------------------------------------ 22.0/455.9 MB 11.9 MB/s eta 0:00:37\n",
      "     - ------------------------------------- 22.3/455.9 MB 9.9 MB/s eta 0:00:44\n",
      "     - ------------------------------------- 22.8/455.9 MB 9.9 MB/s eta 0:00:44\n",
      "     - ------------------------------------- 23.3/455.9 MB 9.9 MB/s eta 0:00:44\n",
      "     -- ------------------------------------ 23.9/455.9 MB 9.9 MB/s eta 0:00:44\n",
      "     -- ------------------------------------ 24.1/455.9 MB 9.9 MB/s eta 0:00:44\n",
      "     -- ------------------------------------ 24.6/455.9 MB 9.6 MB/s eta 0:00:45\n",
      "     -- ------------------------------------ 25.1/455.9 MB 9.8 MB/s eta 0:00:45\n",
      "     -- ------------------------------------ 25.6/455.9 MB 9.6 MB/s eta 0:00:45\n",
      "     -- ------------------------------------ 26.2/455.9 MB 9.6 MB/s eta 0:00:45\n",
      "     -- ------------------------------------ 26.7/455.9 MB 9.6 MB/s eta 0:00:45\n",
      "     -- ------------------------------------ 27.2/455.9 MB 9.6 MB/s eta 0:00:45\n",
      "     -- ------------------------------------ 27.8/455.9 MB 9.8 MB/s eta 0:00:44\n",
      "     -- ------------------------------------ 28.3/455.9 MB 9.6 MB/s eta 0:00:45\n",
      "     -- ------------------------------------ 28.8/455.9 MB 9.6 MB/s eta 0:00:45\n",
      "     -- ------------------------------------ 29.4/455.9 MB 9.6 MB/s eta 0:00:45\n",
      "     -- ------------------------------------ 29.9/455.9 MB 9.8 MB/s eta 0:00:44\n",
      "     -- ------------------------------------ 30.4/455.9 MB 9.6 MB/s eta 0:00:45\n",
      "     -- ------------------------------------ 30.9/455.9 MB 9.6 MB/s eta 0:00:45\n",
      "     -- ------------------------------------ 31.5/455.9 MB 9.6 MB/s eta 0:00:45\n",
      "     -- ------------------------------------ 32.0/455.9 MB 9.6 MB/s eta 0:00:45\n",
      "     -- ----------------------------------- 32.5/455.9 MB 11.3 MB/s eta 0:00:38\n",
      "     -- ----------------------------------- 33.0/455.9 MB 11.3 MB/s eta 0:00:38\n",
      "     -- ----------------------------------- 33.6/455.9 MB 11.5 MB/s eta 0:00:37\n",
      "     -- ----------------------------------- 34.1/455.9 MB 11.5 MB/s eta 0:00:37\n",
      "     -- ----------------------------------- 34.6/455.9 MB 11.9 MB/s eta 0:00:36\n",
      "     -- ----------------------------------- 35.2/455.9 MB 11.9 MB/s eta 0:00:36\n",
      "     -- ----------------------------------- 35.7/455.9 MB 11.9 MB/s eta 0:00:36\n",
      "     --- ---------------------------------- 36.2/455.9 MB 11.7 MB/s eta 0:00:36\n",
      "     --- ---------------------------------- 36.8/455.9 MB 11.7 MB/s eta 0:00:36\n",
      "     --- ---------------------------------- 37.3/455.9 MB 11.7 MB/s eta 0:00:36\n",
      "     --- ---------------------------------- 37.8/455.9 MB 11.7 MB/s eta 0:00:36\n",
      "     --- ---------------------------------- 38.4/455.9 MB 11.7 MB/s eta 0:00:36\n",
      "     --- ---------------------------------- 38.9/455.9 MB 11.9 MB/s eta 0:00:36\n",
      "     --- ---------------------------------- 39.4/455.9 MB 11.9 MB/s eta 0:00:36\n",
      "     --- ---------------------------------- 39.9/455.9 MB 11.9 MB/s eta 0:00:35\n",
      "     --- ---------------------------------- 40.5/455.9 MB 11.7 MB/s eta 0:00:36\n",
      "     --- ---------------------------------- 41.0/455.9 MB 11.7 MB/s eta 0:00:36\n",
      "     --- ---------------------------------- 41.5/455.9 MB 11.7 MB/s eta 0:00:36\n",
      "     --- ---------------------------------- 42.1/455.9 MB 11.7 MB/s eta 0:00:36\n",
      "     --- ---------------------------------- 42.6/455.9 MB 11.7 MB/s eta 0:00:36\n",
      "     --- ---------------------------------- 43.2/455.9 MB 11.9 MB/s eta 0:00:35\n",
      "     --- ---------------------------------- 43.7/455.9 MB 11.9 MB/s eta 0:00:35\n",
      "     --- ---------------------------------- 44.2/455.9 MB 11.9 MB/s eta 0:00:35\n",
      "     --- ---------------------------------- 44.7/455.9 MB 11.9 MB/s eta 0:00:35\n",
      "     --- ---------------------------------- 45.3/455.9 MB 11.7 MB/s eta 0:00:36\n",
      "     --- ---------------------------------- 45.8/455.9 MB 11.7 MB/s eta 0:00:36\n",
      "     --- ---------------------------------- 46.3/455.9 MB 11.7 MB/s eta 0:00:36\n",
      "     --- ---------------------------------- 46.8/455.9 MB 11.7 MB/s eta 0:00:35\n",
      "     --- ---------------------------------- 47.4/455.9 MB 11.9 MB/s eta 0:00:35\n",
      "     --- ---------------------------------- 47.9/455.9 MB 11.9 MB/s eta 0:00:35\n",
      "     ---- --------------------------------- 48.4/455.9 MB 11.9 MB/s eta 0:00:35\n",
      "     ---- --------------------------------- 49.0/455.9 MB 11.9 MB/s eta 0:00:35\n",
      "     ---- --------------------------------- 49.5/455.9 MB 11.7 MB/s eta 0:00:35\n",
      "     ---- --------------------------------- 50.0/455.9 MB 11.7 MB/s eta 0:00:35\n",
      "     ---- --------------------------------- 50.6/455.9 MB 11.7 MB/s eta 0:00:35\n",
      "     ---- --------------------------------- 51.1/455.9 MB 11.7 MB/s eta 0:00:35\n",
      "     ---- --------------------------------- 51.6/455.9 MB 11.7 MB/s eta 0:00:35\n",
      "     ---- --------------------------------- 52.2/455.9 MB 11.9 MB/s eta 0:00:34\n",
      "     ---- --------------------------------- 52.6/455.9 MB 11.9 MB/s eta 0:00:34\n",
      "     ---- --------------------------------- 53.2/455.9 MB 11.7 MB/s eta 0:00:35\n",
      "     ---- --------------------------------- 53.7/455.9 MB 11.7 MB/s eta 0:00:35\n",
      "     ---- --------------------------------- 54.2/455.9 MB 11.7 MB/s eta 0:00:35\n",
      "     ---- --------------------------------- 54.8/455.9 MB 11.7 MB/s eta 0:00:35\n",
      "     ---- --------------------------------- 55.3/455.9 MB 11.7 MB/s eta 0:00:35\n",
      "     ---- --------------------------------- 55.8/455.9 MB 11.7 MB/s eta 0:00:35\n",
      "     ---- --------------------------------- 56.4/455.9 MB 11.7 MB/s eta 0:00:35\n",
      "     ---- --------------------------------- 56.9/455.9 MB 11.9 MB/s eta 0:00:34\n",
      "     ---- --------------------------------- 57.4/455.9 MB 11.7 MB/s eta 0:00:35\n",
      "     ---- --------------------------------- 57.9/455.9 MB 11.7 MB/s eta 0:00:35\n",
      "     ---- --------------------------------- 58.5/455.9 MB 11.7 MB/s eta 0:00:34\n",
      "     ---- --------------------------------- 59.0/455.9 MB 11.7 MB/s eta 0:00:34\n",
      "     ---- --------------------------------- 59.6/455.9 MB 11.7 MB/s eta 0:00:34\n",
      "     ----- -------------------------------- 60.1/455.9 MB 11.7 MB/s eta 0:00:34\n",
      "     ----- -------------------------------- 60.6/455.9 MB 11.7 MB/s eta 0:00:34\n",
      "     ----- -------------------------------- 61.2/455.9 MB 11.7 MB/s eta 0:00:34\n",
      "     ----- -------------------------------- 61.7/455.9 MB 11.9 MB/s eta 0:00:34\n",
      "     ----- -------------------------------- 62.2/455.9 MB 11.7 MB/s eta 0:00:34\n",
      "     ----- -------------------------------- 62.8/455.9 MB 11.9 MB/s eta 0:00:34\n",
      "     ----- -------------------------------- 63.3/455.9 MB 11.9 MB/s eta 0:00:33\n",
      "     ----- -------------------------------- 63.7/455.9 MB 11.7 MB/s eta 0:00:34\n",
      "     ----- -------------------------------- 64.3/455.9 MB 11.7 MB/s eta 0:00:34\n",
      "     ----- -------------------------------- 64.9/455.9 MB 11.7 MB/s eta 0:00:34\n",
      "     ----- -------------------------------- 65.4/455.9 MB 11.7 MB/s eta 0:00:34\n",
      "     ----- -------------------------------- 65.9/455.9 MB 11.7 MB/s eta 0:00:34\n",
      "     ----- -------------------------------- 66.4/455.9 MB 11.9 MB/s eta 0:00:33\n",
      "     ----- -------------------------------- 67.0/455.9 MB 11.9 MB/s eta 0:00:33\n",
      "     ----- -------------------------------- 67.6/455.9 MB 11.9 MB/s eta 0:00:33\n",
      "     ----- -------------------------------- 68.1/455.9 MB 11.9 MB/s eta 0:00:33\n",
      "     ----- -------------------------------- 68.6/455.9 MB 11.9 MB/s eta 0:00:33\n",
      "     ----- -------------------------------- 69.2/455.9 MB 11.9 MB/s eta 0:00:33\n",
      "     ----- -------------------------------- 69.7/455.9 MB 11.7 MB/s eta 0:00:34\n",
      "     ----- -------------------------------- 70.2/455.9 MB 11.7 MB/s eta 0:00:33\n",
      "     ----- -------------------------------- 70.8/455.9 MB 11.7 MB/s eta 0:00:33\n",
      "     ----- -------------------------------- 71.3/455.9 MB 11.7 MB/s eta 0:00:33\n",
      "     ----- -------------------------------- 71.8/455.9 MB 11.7 MB/s eta 0:00:33\n",
      "     ------ ------------------------------- 72.4/455.9 MB 11.9 MB/s eta 0:00:33\n",
      "     ------ ------------------------------- 72.9/455.9 MB 11.9 MB/s eta 0:00:33\n",
      "     ------ ------------------------------- 73.4/455.9 MB 11.9 MB/s eta 0:00:33\n",
      "     ------ ------------------------------- 73.9/455.9 MB 11.9 MB/s eta 0:00:33\n",
      "     ------ ------------------------------- 74.4/455.9 MB 11.9 MB/s eta 0:00:33\n",
      "     ------ ------------------------------- 75.0/455.9 MB 11.7 MB/s eta 0:00:33\n",
      "     ------ ------------------------------- 75.5/455.9 MB 11.7 MB/s eta 0:00:33\n",
      "     ------ ------------------------------- 76.1/455.9 MB 11.7 MB/s eta 0:00:33\n",
      "     ------ ------------------------------- 76.6/455.9 MB 11.7 MB/s eta 0:00:33\n",
      "     ------ ------------------------------- 77.1/455.9 MB 11.9 MB/s eta 0:00:32\n",
      "     ------ ------------------------------- 77.7/455.9 MB 11.9 MB/s eta 0:00:32\n",
      "     ------ ------------------------------- 78.2/455.9 MB 11.9 MB/s eta 0:00:32\n",
      "     ------ ------------------------------- 78.7/455.9 MB 11.7 MB/s eta 0:00:33\n",
      "     ------ ------------------------------- 79.2/455.9 MB 11.7 MB/s eta 0:00:33\n",
      "     ------ ------------------------------- 79.8/455.9 MB 11.7 MB/s eta 0:00:33\n",
      "     ------ ------------------------------- 80.3/455.9 MB 11.7 MB/s eta 0:00:33\n",
      "     ------ ------------------------------- 80.8/455.9 MB 11.7 MB/s eta 0:00:33\n",
      "     ------ ------------------------------- 81.4/455.9 MB 11.9 MB/s eta 0:00:32\n",
      "     ------ ------------------------------- 81.9/455.9 MB 11.9 MB/s eta 0:00:32\n",
      "     ------ ------------------------------- 82.4/455.9 MB 11.9 MB/s eta 0:00:32\n",
      "     ------ ------------------------------- 83.0/455.9 MB 11.9 MB/s eta 0:00:32\n",
      "     ------ ------------------------------- 83.5/455.9 MB 11.7 MB/s eta 0:00:32\n",
      "     ------- ------------------------------ 84.0/455.9 MB 11.7 MB/s eta 0:00:32\n",
      "     ------- ------------------------------ 84.5/455.9 MB 11.7 MB/s eta 0:00:32\n",
      "     ------- ------------------------------ 85.0/455.9 MB 11.7 MB/s eta 0:00:32\n",
      "     ------- ------------------------------ 85.6/455.9 MB 11.9 MB/s eta 0:00:32\n",
      "     ------- ------------------------------ 86.0/455.9 MB 11.7 MB/s eta 0:00:32\n",
      "     ------- ------------------------------ 86.6/455.9 MB 11.7 MB/s eta 0:00:32\n",
      "     ------- ------------------------------ 87.1/455.9 MB 11.7 MB/s eta 0:00:32\n",
      "     ------- ------------------------------ 87.7/455.9 MB 11.7 MB/s eta 0:00:32\n",
      "     ------- ------------------------------ 88.2/455.9 MB 11.7 MB/s eta 0:00:32\n",
      "     ------- ------------------------------ 88.7/455.9 MB 11.7 MB/s eta 0:00:32\n",
      "     ------- ------------------------------ 89.2/455.9 MB 11.7 MB/s eta 0:00:32\n",
      "     ------- ------------------------------ 89.7/455.9 MB 11.7 MB/s eta 0:00:32\n",
      "     ------- ------------------------------ 90.3/455.9 MB 11.9 MB/s eta 0:00:31\n",
      "     ------- ------------------------------ 90.8/455.9 MB 11.7 MB/s eta 0:00:32\n",
      "     ------- ------------------------------ 91.4/455.9 MB 11.7 MB/s eta 0:00:32\n",
      "     ------- ------------------------------ 91.9/455.9 MB 11.7 MB/s eta 0:00:32\n",
      "     ------- ------------------------------ 92.4/455.9 MB 11.7 MB/s eta 0:00:32\n",
      "     ------- ------------------------------ 93.0/455.9 MB 11.7 MB/s eta 0:00:32\n",
      "     ------- ------------------------------ 93.5/455.9 MB 11.7 MB/s eta 0:00:32\n",
      "     ------- ------------------------------ 94.0/455.9 MB 11.7 MB/s eta 0:00:31\n",
      "     ------- ------------------------------ 94.6/455.9 MB 11.9 MB/s eta 0:00:31\n",
      "     ------- ------------------------------ 95.1/455.9 MB 11.9 MB/s eta 0:00:31\n",
      "     ------- ------------------------------ 95.6/455.9 MB 11.9 MB/s eta 0:00:31\n",
      "     -------- ----------------------------- 96.2/455.9 MB 11.9 MB/s eta 0:00:31\n",
      "     -------- ----------------------------- 96.7/455.9 MB 11.7 MB/s eta 0:00:31\n",
      "     -------- ----------------------------- 97.2/455.9 MB 11.9 MB/s eta 0:00:31\n",
      "     -------- ----------------------------- 97.8/455.9 MB 11.7 MB/s eta 0:00:31\n",
      "     -------- ----------------------------- 98.3/455.9 MB 11.7 MB/s eta 0:00:31\n",
      "     -------- ----------------------------- 98.8/455.9 MB 11.9 MB/s eta 0:00:31\n",
      "     -------- ----------------------------- 99.3/455.9 MB 11.7 MB/s eta 0:00:31\n",
      "     -------- ----------------------------- 99.9/455.9 MB 11.9 MB/s eta 0:00:30\n",
      "     -------- ---------------------------- 100.4/455.9 MB 11.9 MB/s eta 0:00:30\n",
      "     -------- ---------------------------- 100.9/455.9 MB 11.9 MB/s eta 0:00:30\n",
      "     -------- ---------------------------- 101.5/455.9 MB 11.9 MB/s eta 0:00:30\n",
      "     -------- ---------------------------- 102.0/455.9 MB 11.7 MB/s eta 0:00:31\n",
      "     -------- ---------------------------- 102.5/455.9 MB 11.7 MB/s eta 0:00:31\n",
      "     -------- ---------------------------- 103.1/455.9 MB 11.7 MB/s eta 0:00:31\n",
      "     -------- ---------------------------- 103.6/455.9 MB 11.7 MB/s eta 0:00:31\n",
      "     -------- ---------------------------- 104.2/455.9 MB 11.9 MB/s eta 0:00:30\n",
      "     -------- ---------------------------- 104.7/455.9 MB 11.9 MB/s eta 0:00:30\n",
      "     -------- ---------------------------- 105.2/455.9 MB 11.9 MB/s eta 0:00:30\n",
      "     -------- ---------------------------- 105.7/455.9 MB 11.9 MB/s eta 0:00:30\n",
      "     -------- ---------------------------- 106.3/455.9 MB 11.7 MB/s eta 0:00:30\n",
      "     -------- ---------------------------- 106.8/455.9 MB 11.7 MB/s eta 0:00:30\n",
      "     -------- ---------------------------- 107.3/455.9 MB 11.7 MB/s eta 0:00:30\n",
      "     -------- ---------------------------- 107.9/455.9 MB 11.7 MB/s eta 0:00:30\n",
      "     -------- ---------------------------- 108.4/455.9 MB 11.9 MB/s eta 0:00:30\n",
      "     -------- ---------------------------- 108.9/455.9 MB 11.9 MB/s eta 0:00:30\n",
      "     -------- ---------------------------- 109.4/455.9 MB 11.9 MB/s eta 0:00:30\n",
      "     -------- ---------------------------- 110.0/455.9 MB 11.9 MB/s eta 0:00:30\n",
      "     -------- ---------------------------- 110.5/455.9 MB 11.7 MB/s eta 0:00:30\n",
      "     --------- --------------------------- 111.0/455.9 MB 11.9 MB/s eta 0:00:30\n",
      "     --------- --------------------------- 111.6/455.9 MB 11.7 MB/s eta 0:00:30\n",
      "     --------- --------------------------- 112.1/455.9 MB 11.7 MB/s eta 0:00:30\n",
      "     --------- --------------------------- 112.6/455.9 MB 11.9 MB/s eta 0:00:29\n",
      "     --------- --------------------------- 113.2/455.9 MB 11.9 MB/s eta 0:00:29\n",
      "     --------- --------------------------- 113.7/455.9 MB 11.9 MB/s eta 0:00:29\n",
      "     --------- --------------------------- 114.2/455.9 MB 11.9 MB/s eta 0:00:29\n",
      "     --------- --------------------------- 114.8/455.9 MB 11.9 MB/s eta 0:00:29\n",
      "     --------- --------------------------- 115.3/455.9 MB 11.7 MB/s eta 0:00:30\n",
      "     --------- --------------------------- 115.8/455.9 MB 11.7 MB/s eta 0:00:30\n",
      "     --------- --------------------------- 116.4/455.9 MB 11.7 MB/s eta 0:00:30\n",
      "     --------- --------------------------- 116.9/455.9 MB 11.7 MB/s eta 0:00:30\n",
      "     --------- --------------------------- 117.4/455.9 MB 11.9 MB/s eta 0:00:29\n",
      "     --------- --------------------------- 118.0/455.9 MB 11.9 MB/s eta 0:00:29\n",
      "     --------- --------------------------- 118.5/455.9 MB 11.9 MB/s eta 0:00:29\n",
      "     --------- --------------------------- 119.0/455.9 MB 11.9 MB/s eta 0:00:29\n",
      "     --------- --------------------------- 119.6/455.9 MB 11.9 MB/s eta 0:00:29\n",
      "     --------- --------------------------- 120.1/455.9 MB 11.7 MB/s eta 0:00:29\n",
      "     --------- --------------------------- 120.6/455.9 MB 11.7 MB/s eta 0:00:29\n",
      "     --------- --------------------------- 121.2/455.9 MB 11.7 MB/s eta 0:00:29\n",
      "     --------- --------------------------- 121.7/455.9 MB 11.7 MB/s eta 0:00:29\n",
      "     --------- --------------------------- 122.2/455.9 MB 11.7 MB/s eta 0:00:29\n",
      "     --------- --------------------------- 122.7/455.9 MB 11.7 MB/s eta 0:00:29\n",
      "     ---------- -------------------------- 123.3/455.9 MB 11.9 MB/s eta 0:00:28\n",
      "     ---------- -------------------------- 123.8/455.9 MB 11.9 MB/s eta 0:00:28\n",
      "     ---------- -------------------------- 124.3/455.9 MB 11.9 MB/s eta 0:00:28\n",
      "     ---------- -------------------------- 124.9/455.9 MB 11.7 MB/s eta 0:00:29\n",
      "     ---------- -------------------------- 125.4/455.9 MB 11.7 MB/s eta 0:00:29\n",
      "     ---------- -------------------------- 125.9/455.9 MB 11.9 MB/s eta 0:00:28\n",
      "     ---------- -------------------------- 126.5/455.9 MB 11.7 MB/s eta 0:00:29\n",
      "     ---------- -------------------------- 127.0/455.9 MB 11.7 MB/s eta 0:00:29\n",
      "     ---------- -------------------------- 127.5/455.9 MB 11.9 MB/s eta 0:00:28\n",
      "     ---------- -------------------------- 128.1/455.9 MB 11.9 MB/s eta 0:00:28\n",
      "     ---------- -------------------------- 128.6/455.9 MB 11.9 MB/s eta 0:00:28\n",
      "     ---------- -------------------------- 129.1/455.9 MB 11.9 MB/s eta 0:00:28\n",
      "     ---------- -------------------------- 129.7/455.9 MB 11.9 MB/s eta 0:00:28\n",
      "     ---------- -------------------------- 130.2/455.9 MB 11.7 MB/s eta 0:00:28\n",
      "     ---------- -------------------------- 130.7/455.9 MB 11.7 MB/s eta 0:00:28\n",
      "     ---------- -------------------------- 131.3/455.9 MB 11.7 MB/s eta 0:00:28\n",
      "     ---------- -------------------------- 131.8/455.9 MB 11.7 MB/s eta 0:00:28\n",
      "     ---------- -------------------------- 132.2/455.9 MB 11.9 MB/s eta 0:00:28\n",
      "     ---------- -------------------------- 132.9/455.9 MB 11.9 MB/s eta 0:00:28\n",
      "     ---------- -------------------------- 133.4/455.9 MB 11.9 MB/s eta 0:00:28\n",
      "     ---------- -------------------------- 133.9/455.9 MB 11.9 MB/s eta 0:00:28\n",
      "     ---------- -------------------------- 134.5/455.9 MB 11.7 MB/s eta 0:00:28\n",
      "     ---------- -------------------------- 135.0/455.9 MB 11.7 MB/s eta 0:00:28\n",
      "     ---------- -------------------------- 135.5/455.9 MB 11.7 MB/s eta 0:00:28\n",
      "     ----------- ------------------------- 136.1/455.9 MB 11.7 MB/s eta 0:00:28\n",
      "     ----------- ------------------------- 136.6/455.9 MB 11.7 MB/s eta 0:00:28\n",
      "     ----------- ------------------------- 137.1/455.9 MB 11.9 MB/s eta 0:00:27\n",
      "     ----------- ------------------------- 137.7/455.9 MB 11.9 MB/s eta 0:00:27\n",
      "     ----------- ------------------------- 138.2/455.9 MB 11.9 MB/s eta 0:00:27\n",
      "     ----------- ------------------------- 138.7/455.9 MB 11.9 MB/s eta 0:00:27\n",
      "     ----------- ------------------------- 139.2/455.9 MB 11.7 MB/s eta 0:00:28\n",
      "     ----------- ------------------------- 139.8/455.9 MB 11.7 MB/s eta 0:00:28\n",
      "     ----------- ------------------------- 140.3/455.9 MB 11.7 MB/s eta 0:00:27\n",
      "     ----------- ------------------------- 140.8/455.9 MB 11.7 MB/s eta 0:00:27\n",
      "     ----------- ------------------------- 141.4/455.9 MB 11.9 MB/s eta 0:00:27\n",
      "     ----------- ------------------------- 141.9/455.9 MB 11.9 MB/s eta 0:00:27\n",
      "     ----------- ------------------------- 142.4/455.9 MB 12.1 MB/s eta 0:00:26\n",
      "     ----------- ------------------------- 143.0/455.9 MB 11.9 MB/s eta 0:00:27\n",
      "     ----------- ------------------------- 143.5/455.9 MB 11.7 MB/s eta 0:00:27\n",
      "     ----------- ------------------------- 144.0/455.9 MB 11.7 MB/s eta 0:00:27\n",
      "     ----------- ------------------------- 144.5/455.9 MB 11.7 MB/s eta 0:00:27\n",
      "     ----------- ------------------------- 145.1/455.9 MB 11.7 MB/s eta 0:00:27\n",
      "     ----------- ------------------------- 145.6/455.9 MB 11.9 MB/s eta 0:00:27\n",
      "     ----------- ------------------------- 146.1/455.9 MB 11.9 MB/s eta 0:00:27\n",
      "     ----------- ------------------------- 146.6/455.9 MB 11.7 MB/s eta 0:00:27\n",
      "     ----------- ------------------------- 147.2/455.9 MB 11.9 MB/s eta 0:00:26\n",
      "     ----------- ------------------------- 147.7/455.9 MB 11.7 MB/s eta 0:00:27\n",
      "     ----------- ------------------------- 147.8/455.9 MB 11.7 MB/s eta 0:00:27\n",
      "     ------------ ------------------------ 148.2/455.9 MB 11.1 MB/s eta 0:00:28\n",
      "     ------------ ------------------------ 148.8/455.9 MB 11.1 MB/s eta 0:00:28\n",
      "     ------------ ------------------------ 149.3/455.9 MB 11.3 MB/s eta 0:00:28\n",
      "     ------------ ------------------------ 149.8/455.9 MB 11.3 MB/s eta 0:00:28\n",
      "     ------------ ------------------------ 150.4/455.9 MB 11.3 MB/s eta 0:00:28\n",
      "     ------------ ------------------------ 150.9/455.9 MB 11.3 MB/s eta 0:00:28\n",
      "     ------------ ------------------------ 151.4/455.9 MB 11.3 MB/s eta 0:00:27\n",
      "     ------------ ------------------------ 152.0/455.9 MB 11.3 MB/s eta 0:00:27\n",
      "     ------------ ------------------------ 152.5/455.9 MB 11.1 MB/s eta 0:00:28\n",
      "     ------------ ------------------------ 153.0/455.9 MB 11.1 MB/s eta 0:00:28\n",
      "     ------------ ------------------------ 153.6/455.9 MB 11.3 MB/s eta 0:00:27\n",
      "     ------------ ------------------------ 154.1/455.9 MB 11.3 MB/s eta 0:00:27\n",
      "     ------------ ------------------------ 154.6/455.9 MB 11.3 MB/s eta 0:00:27\n",
      "     ------------ ------------------------ 155.2/455.9 MB 11.3 MB/s eta 0:00:27\n",
      "     ------------ ------------------------ 155.7/455.9 MB 11.3 MB/s eta 0:00:27\n",
      "     ------------ ------------------------ 156.2/455.9 MB 11.3 MB/s eta 0:00:27\n",
      "     ------------ ------------------------ 156.8/455.9 MB 11.1 MB/s eta 0:00:27\n",
      "     ------------ ------------------------ 157.3/455.9 MB 11.3 MB/s eta 0:00:27\n",
      "     ------------ ------------------------ 157.8/455.9 MB 11.1 MB/s eta 0:00:27\n",
      "     ------------ ------------------------ 158.4/455.9 MB 11.7 MB/s eta 0:00:26\n",
      "     ------------ ------------------------ 158.9/455.9 MB 11.9 MB/s eta 0:00:25\n",
      "     ------------ ------------------------ 159.4/455.9 MB 11.9 MB/s eta 0:00:25\n",
      "     ------------ ------------------------ 159.9/455.9 MB 11.9 MB/s eta 0:00:25\n",
      "     ------------- ----------------------- 160.5/455.9 MB 11.9 MB/s eta 0:00:25\n",
      "     ------------- ----------------------- 161.0/455.9 MB 11.7 MB/s eta 0:00:26\n",
      "     ------------- ----------------------- 161.5/455.9 MB 11.7 MB/s eta 0:00:26\n",
      "     ------------- ----------------------- 162.1/455.9 MB 11.7 MB/s eta 0:00:26\n",
      "     ------------- ----------------------- 162.6/455.9 MB 11.7 MB/s eta 0:00:26\n",
      "     ------------- ----------------------- 163.1/455.9 MB 11.9 MB/s eta 0:00:25\n",
      "     ------------- ----------------------- 163.7/455.9 MB 11.9 MB/s eta 0:00:25\n",
      "     ------------- ----------------------- 164.2/455.9 MB 11.9 MB/s eta 0:00:25\n",
      "     ------------- ----------------------- 164.7/455.9 MB 11.9 MB/s eta 0:00:25\n",
      "     ------------- ----------------------- 165.3/455.9 MB 11.9 MB/s eta 0:00:25\n",
      "     ------------- ----------------------- 165.8/455.9 MB 11.7 MB/s eta 0:00:25\n",
      "     ------------- ----------------------- 166.3/455.9 MB 11.7 MB/s eta 0:00:25\n",
      "     ------------- ----------------------- 166.9/455.9 MB 11.7 MB/s eta 0:00:25\n",
      "     ------------- ----------------------- 167.4/455.9 MB 11.7 MB/s eta 0:00:25\n",
      "     ------------- ----------------------- 167.9/455.9 MB 11.7 MB/s eta 0:00:25\n",
      "     ------------- ----------------------- 168.5/455.9 MB 11.9 MB/s eta 0:00:25\n",
      "     ------------- ----------------------- 169.0/455.9 MB 11.9 MB/s eta 0:00:25\n",
      "     ------------- ----------------------- 169.5/455.9 MB 11.9 MB/s eta 0:00:25\n",
      "     ------------- ----------------------- 170.1/455.9 MB 11.9 MB/s eta 0:00:25\n",
      "     ------------- ----------------------- 170.6/455.9 MB 11.9 MB/s eta 0:00:24\n",
      "     ------------- ----------------------- 171.1/455.9 MB 11.7 MB/s eta 0:00:25\n",
      "     ------------- ----------------------- 171.7/455.9 MB 11.7 MB/s eta 0:00:25\n",
      "     ------------- ----------------------- 172.2/455.9 MB 11.7 MB/s eta 0:00:25\n",
      "     -------------- ---------------------- 172.7/455.9 MB 11.7 MB/s eta 0:00:25\n",
      "     -------------- ---------------------- 173.3/455.9 MB 11.9 MB/s eta 0:00:24\n",
      "     -------------- ---------------------- 173.8/455.9 MB 11.9 MB/s eta 0:00:24\n",
      "     -------------- ---------------------- 174.3/455.9 MB 11.9 MB/s eta 0:00:24\n",
      "     -------------- ---------------------- 174.9/455.9 MB 11.9 MB/s eta 0:00:24\n",
      "     -------------- ---------------------- 175.4/455.9 MB 11.9 MB/s eta 0:00:24\n",
      "     -------------- ---------------------- 175.9/455.9 MB 11.7 MB/s eta 0:00:24\n",
      "     -------------- ---------------------- 176.2/455.9 MB 11.9 MB/s eta 0:00:24\n",
      "     -------------- ---------------------- 176.2/455.9 MB 11.9 MB/s eta 0:00:24\n",
      "     -------------- ---------------------- 176.2/455.9 MB 11.9 MB/s eta 0:00:24\n",
      "     -------------- ---------------------- 176.2/455.9 MB 11.9 MB/s eta 0:00:24\n",
      "     -------------- ----------------------- 176.3/455.9 MB 9.5 MB/s eta 0:00:30\n",
      "     -------------- ----------------------- 176.8/455.9 MB 9.6 MB/s eta 0:00:30\n",
      "     -------------- ----------------------- 177.3/455.9 MB 9.6 MB/s eta 0:00:29\n",
      "     -------------- ----------------------- 177.9/455.9 MB 9.6 MB/s eta 0:00:29\n",
      "     -------------- ----------------------- 178.4/455.9 MB 9.6 MB/s eta 0:00:29\n",
      "     -------------- ----------------------- 178.9/455.9 MB 9.6 MB/s eta 0:00:29\n",
      "     -------------- ----------------------- 179.4/455.9 MB 9.5 MB/s eta 0:00:30\n",
      "     --------------- ---------------------- 180.0/455.9 MB 9.5 MB/s eta 0:00:30\n",
      "     --------------- ---------------------- 180.4/455.9 MB 9.6 MB/s eta 0:00:29\n",
      "     --------------- ---------------------- 181.0/455.9 MB 9.6 MB/s eta 0:00:29\n",
      "     --------------- ---------------------- 181.6/455.9 MB 9.6 MB/s eta 0:00:29\n",
      "     --------------- ---------------------- 182.1/455.9 MB 9.6 MB/s eta 0:00:29\n",
      "     --------------- ---------------------- 182.6/455.9 MB 9.6 MB/s eta 0:00:29\n",
      "     --------------- ---------------------- 183.2/455.9 MB 9.6 MB/s eta 0:00:29\n",
      "     --------------- ---------------------- 183.7/455.9 MB 9.6 MB/s eta 0:00:29\n",
      "     --------------- ---------------------- 184.3/455.9 MB 9.6 MB/s eta 0:00:29\n",
      "     --------------- ---------------------- 184.8/455.9 MB 9.5 MB/s eta 0:00:29\n",
      "     --------------- ---------------------- 185.3/455.9 MB 9.5 MB/s eta 0:00:29\n",
      "     --------------- ---------------------- 185.9/455.9 MB 9.5 MB/s eta 0:00:29\n",
      "     --------------- ---------------------- 186.4/455.9 MB 9.6 MB/s eta 0:00:28\n",
      "     --------------- --------------------- 186.9/455.9 MB 11.9 MB/s eta 0:00:23\n",
      "     --------------- --------------------- 187.4/455.9 MB 11.9 MB/s eta 0:00:23\n",
      "     --------------- --------------------- 188.0/455.9 MB 11.7 MB/s eta 0:00:23\n",
      "     --------------- --------------------- 188.5/455.9 MB 11.7 MB/s eta 0:00:23\n",
      "     --------------- --------------------- 189.0/455.9 MB 11.7 MB/s eta 0:00:23\n",
      "     --------------- --------------------- 189.6/455.9 MB 11.7 MB/s eta 0:00:23\n",
      "     --------------- --------------------- 190.1/455.9 MB 11.7 MB/s eta 0:00:23\n",
      "     --------------- --------------------- 190.6/455.9 MB 11.9 MB/s eta 0:00:23\n",
      "     --------------- --------------------- 191.2/455.9 MB 11.9 MB/s eta 0:00:23\n",
      "     --------------- --------------------- 191.7/455.9 MB 11.9 MB/s eta 0:00:23\n",
      "     --------------- --------------------- 192.1/455.9 MB 11.7 MB/s eta 0:00:23\n",
      "     --------------- --------------------- 192.7/455.9 MB 11.7 MB/s eta 0:00:23\n",
      "     --------------- --------------------- 193.3/455.9 MB 11.7 MB/s eta 0:00:23\n",
      "     --------------- --------------------- 193.8/455.9 MB 11.7 MB/s eta 0:00:23\n",
      "     --------------- --------------------- 194.3/455.9 MB 11.7 MB/s eta 0:00:23\n",
      "     --------------- --------------------- 194.9/455.9 MB 11.9 MB/s eta 0:00:22\n",
      "     --------------- --------------------- 195.4/455.9 MB 11.9 MB/s eta 0:00:22\n",
      "     --------------- --------------------- 195.9/455.9 MB 11.9 MB/s eta 0:00:22\n",
      "     --------------- --------------------- 196.5/455.9 MB 11.9 MB/s eta 0:00:22\n",
      "     --------------- --------------------- 197.0/455.9 MB 11.9 MB/s eta 0:00:22\n",
      "     ---------------- -------------------- 197.5/455.9 MB 11.7 MB/s eta 0:00:23\n",
      "     ---------------- -------------------- 198.1/455.9 MB 11.7 MB/s eta 0:00:23\n",
      "     ---------------- -------------------- 198.6/455.9 MB 11.7 MB/s eta 0:00:23\n",
      "     ---------------- -------------------- 199.1/455.9 MB 11.7 MB/s eta 0:00:22\n",
      "     ---------------- -------------------- 199.7/455.9 MB 11.7 MB/s eta 0:00:22\n",
      "     ---------------- -------------------- 200.2/455.9 MB 11.9 MB/s eta 0:00:22\n",
      "     ---------------- -------------------- 200.7/455.9 MB 11.9 MB/s eta 0:00:22\n",
      "     ---------------- -------------------- 201.2/455.9 MB 11.9 MB/s eta 0:00:22\n",
      "     ---------------- -------------------- 201.8/455.9 MB 11.9 MB/s eta 0:00:22\n",
      "     ---------------- -------------------- 202.3/455.9 MB 11.7 MB/s eta 0:00:22\n",
      "     ---------------- -------------------- 202.9/455.9 MB 11.7 MB/s eta 0:00:22\n",
      "     ---------------- -------------------- 203.4/455.9 MB 11.7 MB/s eta 0:00:22\n",
      "     ---------------- -------------------- 203.9/455.9 MB 11.7 MB/s eta 0:00:22\n",
      "     ---------------- -------------------- 204.5/455.9 MB 11.7 MB/s eta 0:00:22\n",
      "     ---------------- -------------------- 205.0/455.9 MB 11.9 MB/s eta 0:00:22\n",
      "     ---------------- -------------------- 205.5/455.9 MB 11.9 MB/s eta 0:00:22\n",
      "     ---------------- -------------------- 206.0/455.9 MB 11.9 MB/s eta 0:00:21\n",
      "     ---------------- -------------------- 206.6/455.9 MB 11.9 MB/s eta 0:00:21\n",
      "     ---------------- -------------------- 207.1/455.9 MB 11.7 MB/s eta 0:00:22\n",
      "     ---------------- -------------------- 207.6/455.9 MB 11.7 MB/s eta 0:00:22\n",
      "     ---------------- -------------------- 208.2/455.9 MB 11.7 MB/s eta 0:00:22\n",
      "     ---------------- -------------------- 208.7/455.9 MB 11.7 MB/s eta 0:00:22\n",
      "     ---------------- -------------------- 209.2/455.9 MB 11.9 MB/s eta 0:00:21\n",
      "     ----------------- ------------------- 209.7/455.9 MB 11.9 MB/s eta 0:00:21\n",
      "     ----------------- ------------------- 210.3/455.9 MB 11.9 MB/s eta 0:00:21\n",
      "     ----------------- ------------------- 210.8/455.9 MB 11.9 MB/s eta 0:00:21\n",
      "     ----------------- ------------------- 211.4/455.9 MB 11.9 MB/s eta 0:00:21\n",
      "     ----------------- ------------------- 211.9/455.9 MB 11.7 MB/s eta 0:00:21\n",
      "     ----------------- ------------------- 212.4/455.9 MB 11.7 MB/s eta 0:00:21\n",
      "     ----------------- ------------------- 213.0/455.9 MB 11.7 MB/s eta 0:00:21\n",
      "     ----------------- ------------------- 213.5/455.9 MB 11.7 MB/s eta 0:00:21\n",
      "     ----------------- ------------------- 214.0/455.9 MB 11.9 MB/s eta 0:00:21\n",
      "     ----------------- ------------------- 214.6/455.9 MB 11.9 MB/s eta 0:00:21\n",
      "     ----------------- ------------------- 214.9/455.9 MB 11.9 MB/s eta 0:00:21\n",
      "     ----------------- ------------------- 215.5/455.9 MB 11.7 MB/s eta 0:00:21\n",
      "     ----------------- ------------------- 216.1/455.9 MB 11.7 MB/s eta 0:00:21\n",
      "     ----------------- ------------------- 216.6/455.9 MB 11.7 MB/s eta 0:00:21\n",
      "     ----------------- ------------------- 217.1/455.9 MB 11.7 MB/s eta 0:00:21\n",
      "     ----------------- ------------------- 217.7/455.9 MB 11.7 MB/s eta 0:00:21\n",
      "     ----------------- ------------------- 218.2/455.9 MB 11.7 MB/s eta 0:00:21\n",
      "     ----------------- ------------------- 218.7/455.9 MB 11.9 MB/s eta 0:00:20\n",
      "     ----------------- ------------------- 219.2/455.9 MB 11.7 MB/s eta 0:00:21\n",
      "     ----------------- ------------------- 219.8/455.9 MB 11.7 MB/s eta 0:00:21\n",
      "     ----------------- ------------------- 220.3/455.9 MB 11.7 MB/s eta 0:00:21\n",
      "     ----------------- ------------------- 220.8/455.9 MB 11.7 MB/s eta 0:00:21\n",
      "     ----------------- ------------------- 221.4/455.9 MB 11.7 MB/s eta 0:00:21\n",
      "     ------------------ ------------------ 221.9/455.9 MB 11.7 MB/s eta 0:00:21\n",
      "     ------------------ ------------------ 222.4/455.9 MB 11.9 MB/s eta 0:00:20\n",
      "     ------------------ ------------------ 223.0/455.9 MB 11.9 MB/s eta 0:00:20\n",
      "     ------------------ ------------------ 223.5/455.9 MB 11.9 MB/s eta 0:00:20\n",
      "     ------------------ ------------------ 224.0/455.9 MB 11.7 MB/s eta 0:00:20\n",
      "     ------------------ ------------------ 224.6/455.9 MB 11.7 MB/s eta 0:00:20\n",
      "     ------------------ ------------------ 225.1/455.9 MB 11.7 MB/s eta 0:00:20\n",
      "     ------------------ ------------------ 225.6/455.9 MB 11.7 MB/s eta 0:00:20\n",
      "     ------------------ ------------------ 226.1/455.9 MB 11.7 MB/s eta 0:00:20\n",
      "     ------------------ ------------------ 226.7/455.9 MB 11.7 MB/s eta 0:00:20\n",
      "     ------------------ ------------------ 227.2/455.9 MB 11.9 MB/s eta 0:00:20\n",
      "     ------------------ ------------------ 227.7/455.9 MB 11.9 MB/s eta 0:00:20\n",
      "     ------------------ ------------------ 228.3/455.9 MB 11.9 MB/s eta 0:00:20\n",
      "     ------------------ ------------------ 228.8/455.9 MB 11.9 MB/s eta 0:00:20\n",
      "     ------------------ ------------------ 229.2/455.9 MB 11.9 MB/s eta 0:00:20\n",
      "     ------------------ ------------------ 229.8/455.9 MB 11.7 MB/s eta 0:00:20\n",
      "     ------------------ ------------------ 230.4/455.9 MB 11.7 MB/s eta 0:00:20\n",
      "     ------------------ ------------------ 230.7/455.9 MB 11.9 MB/s eta 0:00:19\n",
      "     ------------------ ------------------ 230.7/455.9 MB 11.9 MB/s eta 0:00:19\n",
      "     ------------------ ------------------ 230.7/455.9 MB 11.9 MB/s eta 0:00:19\n",
      "     ------------------ ------------------ 230.7/455.9 MB 11.9 MB/s eta 0:00:19\n",
      "     ------------------ ------------------ 230.7/455.9 MB 11.9 MB/s eta 0:00:19\n",
      "     ------------------- ------------------ 231.1/455.9 MB 9.5 MB/s eta 0:00:24\n",
      "     ------------------- ------------------ 231.6/455.9 MB 9.5 MB/s eta 0:00:24\n",
      "     ------------------- ------------------ 232.1/455.9 MB 9.5 MB/s eta 0:00:24\n",
      "     ------------------- ------------------ 232.7/455.9 MB 9.4 MB/s eta 0:00:24\n",
      "     ------------------- ------------------ 233.2/455.9 MB 9.4 MB/s eta 0:00:24\n",
      "     ------------------- ------------------ 233.7/455.9 MB 9.4 MB/s eta 0:00:24\n",
      "     ------------------- ------------------ 234.2/455.9 MB 9.4 MB/s eta 0:00:24\n",
      "     ------------------- ------------------ 234.8/455.9 MB 9.5 MB/s eta 0:00:24\n",
      "     ------------------- ------------------ 235.3/455.9 MB 9.5 MB/s eta 0:00:24\n",
      "     ------------------- ------------------ 235.8/455.9 MB 9.5 MB/s eta 0:00:24\n",
      "     ------------------- ------------------ 236.4/455.9 MB 9.5 MB/s eta 0:00:24\n",
      "     ------------------- ------------------ 236.9/455.9 MB 9.5 MB/s eta 0:00:24\n",
      "     ------------------- ------------------ 237.4/455.9 MB 9.4 MB/s eta 0:00:24\n",
      "     ------------------- ------------------ 238.0/455.9 MB 9.4 MB/s eta 0:00:24\n",
      "     ------------------- ------------------ 238.5/455.9 MB 9.4 MB/s eta 0:00:24\n",
      "     ------------------- ------------------ 239.0/455.9 MB 9.4 MB/s eta 0:00:24\n",
      "     ------------------- ------------------ 239.6/455.9 MB 9.6 MB/s eta 0:00:23\n",
      "     -------------------- ----------------- 240.1/455.9 MB 9.5 MB/s eta 0:00:23\n",
      "     -------------------- ----------------- 240.6/455.9 MB 9.5 MB/s eta 0:00:23\n",
      "     ------------------- ----------------- 241.2/455.9 MB 11.9 MB/s eta 0:00:19\n",
      "     ------------------- ----------------- 241.7/455.9 MB 11.7 MB/s eta 0:00:19\n",
      "     ------------------- ----------------- 242.2/455.9 MB 11.7 MB/s eta 0:00:19\n",
      "     ------------------- ----------------- 242.8/455.9 MB 11.7 MB/s eta 0:00:19\n",
      "     ------------------- ----------------- 243.3/455.9 MB 11.7 MB/s eta 0:00:19\n",
      "     ------------------- ----------------- 243.8/455.9 MB 11.7 MB/s eta 0:00:19\n",
      "     ------------------- ----------------- 244.4/455.9 MB 11.7 MB/s eta 0:00:19\n",
      "     ------------------- ----------------- 244.9/455.9 MB 11.9 MB/s eta 0:00:18\n",
      "     ------------------- ----------------- 245.3/455.9 MB 11.7 MB/s eta 0:00:19\n",
      "     ------------------- ----------------- 246.0/455.9 MB 11.9 MB/s eta 0:00:18\n",
      "     ------------------- ----------------- 246.4/455.9 MB 11.7 MB/s eta 0:00:18\n",
      "     ------------------- ----------------- 246.4/455.9 MB 11.7 MB/s eta 0:00:18\n",
      "     ------------------- ----------------- 246.4/455.9 MB 11.7 MB/s eta 0:00:18\n",
      "     -------------------- ---------------- 246.7/455.9 MB 10.2 MB/s eta 0:00:21\n",
      "     -------------------- ---------------- 247.2/455.9 MB 10.2 MB/s eta 0:00:21\n",
      "     -------------------- ---------------- 247.6/455.9 MB 10.2 MB/s eta 0:00:21\n",
      "     -------------------- ---------------- 248.2/455.9 MB 10.4 MB/s eta 0:00:20\n",
      "     -------------------- ---------------- 248.8/455.9 MB 10.4 MB/s eta 0:00:20\n",
      "     -------------------- ---------------- 249.3/455.9 MB 10.4 MB/s eta 0:00:20\n",
      "     -------------------- ---------------- 249.8/455.9 MB 10.4 MB/s eta 0:00:20\n",
      "     -------------------- ---------------- 250.4/455.9 MB 10.4 MB/s eta 0:00:20\n",
      "     -------------------- ---------------- 250.9/455.9 MB 10.2 MB/s eta 0:00:21\n",
      "     -------------------- ---------------- 251.4/455.9 MB 10.2 MB/s eta 0:00:20\n",
      "     -------------------- ---------------- 252.0/455.9 MB 10.2 MB/s eta 0:00:20\n",
      "     -------------------- ---------------- 252.5/455.9 MB 10.2 MB/s eta 0:00:20\n",
      "     -------------------- ---------------- 253.0/455.9 MB 10.4 MB/s eta 0:00:20\n",
      "     -------------------- ---------------- 253.6/455.9 MB 10.4 MB/s eta 0:00:20\n",
      "     -------------------- ---------------- 254.1/455.9 MB 10.4 MB/s eta 0:00:20\n",
      "     -------------------- ---------------- 254.6/455.9 MB 10.4 MB/s eta 0:00:20\n",
      "     -------------------- ---------------- 255.1/455.9 MB 10.2 MB/s eta 0:00:20\n",
      "     -------------------- ---------------- 255.7/455.9 MB 10.4 MB/s eta 0:00:20\n",
      "     -------------------- ---------------- 256.2/455.9 MB 10.2 MB/s eta 0:00:20\n",
      "     -------------------- ---------------- 256.7/455.9 MB 11.7 MB/s eta 0:00:18\n",
      "     -------------------- ---------------- 257.2/455.9 MB 11.9 MB/s eta 0:00:17\n",
      "     -------------------- ---------------- 257.8/455.9 MB 11.9 MB/s eta 0:00:17\n",
      "     -------------------- ---------------- 257.9/455.9 MB 11.9 MB/s eta 0:00:17\n",
      "     -------------------- ---------------- 257.9/455.9 MB 11.9 MB/s eta 0:00:17\n",
      "     -------------------- ---------------- 257.9/455.9 MB 11.9 MB/s eta 0:00:17\n",
      "     -------------------- ---------------- 257.9/455.9 MB 11.9 MB/s eta 0:00:17\n",
      "     --------------------- ---------------- 258.2/455.9 MB 9.8 MB/s eta 0:00:21\n",
      "     --------------------- ---------------- 258.8/455.9 MB 9.6 MB/s eta 0:00:21\n",
      "     --------------------- ---------------- 259.3/455.9 MB 9.8 MB/s eta 0:00:21\n",
      "     --------------------- ---------------- 259.9/455.9 MB 9.8 MB/s eta 0:00:21\n",
      "     --------------------- ---------------- 260.4/455.9 MB 9.8 MB/s eta 0:00:21\n",
      "     --------------------- ---------------- 260.9/455.9 MB 9.8 MB/s eta 0:00:20\n",
      "     --------------------- ---------------- 261.4/455.9 MB 9.8 MB/s eta 0:00:20\n",
      "     --------------------- ---------------- 262.0/455.9 MB 9.8 MB/s eta 0:00:20\n",
      "     --------------------- ---------------- 262.5/455.9 MB 9.6 MB/s eta 0:00:21\n",
      "     --------------------- ---------------- 263.0/455.9 MB 9.6 MB/s eta 0:00:21\n",
      "     --------------------- ---------------- 263.6/455.9 MB 9.6 MB/s eta 0:00:20\n",
      "     ---------------------- --------------- 264.1/455.9 MB 9.6 MB/s eta 0:00:20\n",
      "     ---------------------- --------------- 264.6/455.9 MB 9.8 MB/s eta 0:00:20\n",
      "     ---------------------- --------------- 265.2/455.9 MB 9.8 MB/s eta 0:00:20\n",
      "     ---------------------- --------------- 265.7/455.9 MB 9.8 MB/s eta 0:00:20\n",
      "     ---------------------- --------------- 266.2/455.9 MB 9.6 MB/s eta 0:00:20\n",
      "     ---------------------- --------------- 266.8/455.9 MB 9.6 MB/s eta 0:00:20\n",
      "     ---------------------- --------------- 267.3/455.9 MB 9.6 MB/s eta 0:00:20\n",
      "     ---------------------- --------------- 267.8/455.9 MB 9.6 MB/s eta 0:00:20\n",
      "     --------------------- --------------- 268.3/455.9 MB 11.7 MB/s eta 0:00:17\n",
      "     --------------------- --------------- 268.9/455.9 MB 11.9 MB/s eta 0:00:16\n",
      "     --------------------- --------------- 269.4/455.9 MB 11.9 MB/s eta 0:00:16\n",
      "     --------------------- --------------- 269.9/455.9 MB 11.9 MB/s eta 0:00:16\n",
      "     --------------------- --------------- 270.5/455.9 MB 11.9 MB/s eta 0:00:16\n",
      "     --------------------- --------------- 271.0/455.9 MB 11.9 MB/s eta 0:00:16\n",
      "     ---------------------- -------------- 271.5/455.9 MB 11.7 MB/s eta 0:00:16\n",
      "     ---------------------- -------------- 272.1/455.9 MB 11.7 MB/s eta 0:00:16\n",
      "     ---------------------- -------------- 272.6/455.9 MB 11.7 MB/s eta 0:00:16\n",
      "     ---------------------- -------------- 273.1/455.9 MB 11.7 MB/s eta 0:00:16\n",
      "     ---------------------- -------------- 273.7/455.9 MB 11.9 MB/s eta 0:00:16\n",
      "     ---------------------- -------------- 274.2/455.9 MB 11.9 MB/s eta 0:00:16\n",
      "     ---------------------- -------------- 274.7/455.9 MB 11.9 MB/s eta 0:00:16\n",
      "     ---------------------- -------------- 275.3/455.9 MB 11.9 MB/s eta 0:00:16\n",
      "     ---------------------- -------------- 275.8/455.9 MB 11.9 MB/s eta 0:00:16\n",
      "     ---------------------- -------------- 276.3/455.9 MB 11.7 MB/s eta 0:00:16\n",
      "     ---------------------- -------------- 276.8/455.9 MB 11.7 MB/s eta 0:00:16\n",
      "     ---------------------- -------------- 277.4/455.9 MB 11.7 MB/s eta 0:00:16\n",
      "     ---------------------- -------------- 277.9/455.9 MB 11.9 MB/s eta 0:00:15\n",
      "     ---------------------- -------------- 278.4/455.9 MB 11.9 MB/s eta 0:00:15\n",
      "     ---------------------- -------------- 278.9/455.9 MB 11.9 MB/s eta 0:00:15\n",
      "     ---------------------- -------------- 279.5/455.9 MB 11.9 MB/s eta 0:00:15\n",
      "     ---------------------- -------------- 280.0/455.9 MB 11.7 MB/s eta 0:00:16\n",
      "     ---------------------- -------------- 280.5/455.9 MB 11.7 MB/s eta 0:00:16\n",
      "     ---------------------- -------------- 281.1/455.9 MB 11.7 MB/s eta 0:00:15\n",
      "     ---------------------- -------------- 281.6/455.9 MB 11.7 MB/s eta 0:00:15\n",
      "     ---------------------- -------------- 282.1/455.9 MB 11.7 MB/s eta 0:00:15\n",
      "     ---------------------- -------------- 282.7/455.9 MB 11.9 MB/s eta 0:00:15\n",
      "     ---------------------- -------------- 283.2/455.9 MB 11.9 MB/s eta 0:00:15\n",
      "     ----------------------- ------------- 283.8/455.9 MB 11.9 MB/s eta 0:00:15\n",
      "     ----------------------- ------------- 284.3/455.9 MB 11.9 MB/s eta 0:00:15\n",
      "     ----------------------- ------------- 284.8/455.9 MB 11.9 MB/s eta 0:00:15\n",
      "     ----------------------- ------------- 285.4/455.9 MB 11.7 MB/s eta 0:00:15\n",
      "     ----------------------- ------------- 285.9/455.9 MB 11.7 MB/s eta 0:00:15\n",
      "     ----------------------- ------------- 286.4/455.9 MB 11.7 MB/s eta 0:00:15\n",
      "     ----------------------- ------------- 287.0/455.9 MB 11.7 MB/s eta 0:00:15\n",
      "     ----------------------- ------------- 287.5/455.9 MB 11.9 MB/s eta 0:00:15\n",
      "     ----------------------- ------------- 288.0/455.9 MB 11.9 MB/s eta 0:00:15\n",
      "     ----------------------- ------------- 288.6/455.9 MB 11.9 MB/s eta 0:00:15\n",
      "     ----------------------- ------------- 289.1/455.9 MB 11.9 MB/s eta 0:00:15\n",
      "     ----------------------- ------------- 289.6/455.9 MB 11.9 MB/s eta 0:00:14\n",
      "     ----------------------- ------------- 290.2/455.9 MB 11.9 MB/s eta 0:00:14\n",
      "     ----------------------- ------------- 290.7/455.9 MB 11.7 MB/s eta 0:00:15\n",
      "     ----------------------- ------------- 291.2/455.9 MB 11.7 MB/s eta 0:00:15\n",
      "     ----------------------- ------------- 291.8/455.9 MB 11.7 MB/s eta 0:00:15\n",
      "     ----------------------- ------------- 292.3/455.9 MB 11.7 MB/s eta 0:00:14\n",
      "     ----------------------- ------------- 292.8/455.9 MB 11.7 MB/s eta 0:00:14\n",
      "     ----------------------- ------------- 293.4/455.9 MB 11.9 MB/s eta 0:00:14\n",
      "     ----------------------- ------------- 293.7/455.9 MB 11.9 MB/s eta 0:00:14\n",
      "     ----------------------- ------------- 294.4/455.9 MB 11.9 MB/s eta 0:00:14\n",
      "     ----------------------- ------------- 295.0/455.9 MB 11.9 MB/s eta 0:00:14\n",
      "     ----------------------- ------------- 295.5/455.9 MB 11.7 MB/s eta 0:00:14\n",
      "     ------------------------ ------------ 296.0/455.9 MB 11.7 MB/s eta 0:00:14\n",
      "     ------------------------ ------------ 296.6/455.9 MB 11.7 MB/s eta 0:00:14\n",
      "     ------------------------ ------------ 297.1/455.9 MB 11.7 MB/s eta 0:00:14\n",
      "     ------------------------ ------------ 297.6/455.9 MB 11.9 MB/s eta 0:00:14\n",
      "     ------------------------ ------------ 298.1/455.9 MB 11.9 MB/s eta 0:00:14\n",
      "     ------------------------ ------------ 298.7/455.9 MB 11.9 MB/s eta 0:00:14\n",
      "     ------------------------ ------------ 299.2/455.9 MB 11.9 MB/s eta 0:00:14\n",
      "     ------------------------ ------------ 299.7/455.9 MB 11.7 MB/s eta 0:00:14\n",
      "     ------------------------ ------------ 300.3/455.9 MB 11.7 MB/s eta 0:00:14\n",
      "     ------------------------ ------------ 300.8/455.9 MB 11.7 MB/s eta 0:00:14\n",
      "     ------------------------ ------------ 301.3/455.9 MB 11.7 MB/s eta 0:00:14\n",
      "     ------------------------ ------------ 301.9/455.9 MB 11.7 MB/s eta 0:00:14\n",
      "     ------------------------ ------------ 302.4/455.9 MB 11.9 MB/s eta 0:00:13\n",
      "     ------------------------ ------------ 302.9/455.9 MB 11.9 MB/s eta 0:00:13\n",
      "     ------------------------ ------------ 303.4/455.9 MB 11.9 MB/s eta 0:00:13\n",
      "     ------------------------ ------------ 304.0/455.9 MB 11.7 MB/s eta 0:00:13\n",
      "     ------------------------ ------------ 304.5/455.9 MB 11.7 MB/s eta 0:00:13\n",
      "     ------------------------ ------------ 305.0/455.9 MB 11.7 MB/s eta 0:00:13\n",
      "     ------------------------ ------------ 305.6/455.9 MB 11.7 MB/s eta 0:00:13\n",
      "     ------------------------ ------------ 306.1/455.9 MB 11.9 MB/s eta 0:00:13\n",
      "     ------------------------ ------------ 306.6/455.9 MB 11.9 MB/s eta 0:00:13\n",
      "     ------------------------ ------------ 307.1/455.9 MB 11.9 MB/s eta 0:00:13\n",
      "     ------------------------ ------------ 307.7/455.9 MB 11.9 MB/s eta 0:00:13\n",
      "     ------------------------- ----------- 308.2/455.9 MB 11.9 MB/s eta 0:00:13\n",
      "     ------------------------- ----------- 308.7/455.9 MB 11.7 MB/s eta 0:00:13\n",
      "     ------------------------- ----------- 309.3/455.9 MB 11.7 MB/s eta 0:00:13\n",
      "     ------------------------- ----------- 309.8/455.9 MB 11.7 MB/s eta 0:00:13\n",
      "     ------------------------- ----------- 310.3/455.9 MB 11.7 MB/s eta 0:00:13\n",
      "     ------------------------- ----------- 310.9/455.9 MB 11.9 MB/s eta 0:00:13\n",
      "     ------------------------- ----------- 311.4/455.9 MB 11.9 MB/s eta 0:00:13\n",
      "     ------------------------- ----------- 312.0/455.9 MB 11.9 MB/s eta 0:00:13\n",
      "     ------------------------- ----------- 312.5/455.9 MB 11.9 MB/s eta 0:00:13\n",
      "     ------------------------- ----------- 313.0/455.9 MB 11.7 MB/s eta 0:00:13\n",
      "     ------------------------- ----------- 313.5/455.9 MB 11.7 MB/s eta 0:00:13\n",
      "     ------------------------- ----------- 314.1/455.9 MB 11.7 MB/s eta 0:00:13\n",
      "     ------------------------- ----------- 314.6/455.9 MB 11.7 MB/s eta 0:00:13\n",
      "     ------------------------- ----------- 315.1/455.9 MB 11.7 MB/s eta 0:00:13\n",
      "     ------------------------- ----------- 315.7/455.9 MB 11.9 MB/s eta 0:00:12\n",
      "     ------------------------- ----------- 316.2/455.9 MB 11.9 MB/s eta 0:00:12\n",
      "     ------------------------- ----------- 316.7/455.9 MB 11.9 MB/s eta 0:00:12\n",
      "     ------------------------- ----------- 317.2/455.9 MB 11.7 MB/s eta 0:00:12\n",
      "     ------------------------- ----------- 317.8/455.9 MB 11.7 MB/s eta 0:00:12\n",
      "     ------------------------- ----------- 318.2/455.9 MB 11.7 MB/s eta 0:00:12\n",
      "     ------------------------- ----------- 318.8/455.9 MB 11.7 MB/s eta 0:00:12\n",
      "     ------------------------- ----------- 319.3/455.9 MB 11.9 MB/s eta 0:00:12\n",
      "     ------------------------- ----------- 319.9/455.9 MB 11.9 MB/s eta 0:00:12\n",
      "     -------------------------- ---------- 320.4/455.9 MB 12.1 MB/s eta 0:00:12\n",
      "     -------------------------- ---------- 320.9/455.9 MB 11.9 MB/s eta 0:00:12\n",
      "     -------------------------- ---------- 321.5/455.9 MB 11.7 MB/s eta 0:00:12\n",
      "     -------------------------- ---------- 322.0/455.9 MB 11.7 MB/s eta 0:00:12\n",
      "     -------------------------- ---------- 322.5/455.9 MB 11.7 MB/s eta 0:00:12\n",
      "     -------------------------- ---------- 323.1/455.9 MB 11.7 MB/s eta 0:00:12\n",
      "     -------------------------- ---------- 323.6/455.9 MB 11.7 MB/s eta 0:00:12\n",
      "     -------------------------- ---------- 324.1/455.9 MB 11.9 MB/s eta 0:00:12\n",
      "     -------------------------- ---------- 324.6/455.9 MB 11.9 MB/s eta 0:00:12\n",
      "     -------------------------- ---------- 325.2/455.9 MB 11.9 MB/s eta 0:00:11\n",
      "     -------------------------- ---------- 325.7/455.9 MB 11.9 MB/s eta 0:00:11\n",
      "     -------------------------- ---------- 326.3/455.9 MB 11.9 MB/s eta 0:00:11\n",
      "     -------------------------- ---------- 326.8/455.9 MB 11.7 MB/s eta 0:00:12\n",
      "     -------------------------- ---------- 327.3/455.9 MB 11.7 MB/s eta 0:00:12\n",
      "     -------------------------- ---------- 327.8/455.9 MB 11.7 MB/s eta 0:00:11\n",
      "     -------------------------- ---------- 328.4/455.9 MB 11.9 MB/s eta 0:00:11\n",
      "     -------------------------- ---------- 328.9/455.9 MB 11.9 MB/s eta 0:00:11\n",
      "     -------------------------- ---------- 329.4/455.9 MB 11.9 MB/s eta 0:00:11\n",
      "     -------------------------- ---------- 330.0/455.9 MB 11.9 MB/s eta 0:00:11\n",
      "     -------------------------- ---------- 330.5/455.9 MB 11.7 MB/s eta 0:00:11\n",
      "     -------------------------- ---------- 331.0/455.9 MB 11.7 MB/s eta 0:00:11\n",
      "     -------------------------- ---------- 331.6/455.9 MB 11.7 MB/s eta 0:00:11\n",
      "     -------------------------- ---------- 332.1/455.9 MB 11.7 MB/s eta 0:00:11\n",
      "     -------------------------- ---------- 332.6/455.9 MB 11.7 MB/s eta 0:00:11\n",
      "     --------------------------- --------- 333.2/455.9 MB 11.9 MB/s eta 0:00:11\n",
      "     --------------------------- --------- 333.7/455.9 MB 11.9 MB/s eta 0:00:11\n",
      "     --------------------------- --------- 334.2/455.9 MB 11.9 MB/s eta 0:00:11\n",
      "     --------------------------- --------- 334.8/455.9 MB 11.9 MB/s eta 0:00:11\n",
      "     --------------------------- --------- 335.3/455.9 MB 11.7 MB/s eta 0:00:11\n",
      "     --------------------------- --------- 335.8/455.9 MB 11.7 MB/s eta 0:00:11\n",
      "     --------------------------- --------- 336.4/455.9 MB 11.9 MB/s eta 0:00:11\n",
      "     --------------------------- --------- 336.9/455.9 MB 11.7 MB/s eta 0:00:11\n",
      "     --------------------------- --------- 337.4/455.9 MB 11.9 MB/s eta 0:00:10\n",
      "     --------------------------- --------- 337.9/455.9 MB 11.9 MB/s eta 0:00:10\n",
      "     --------------------------- --------- 338.4/455.9 MB 11.9 MB/s eta 0:00:10\n",
      "     --------------------------- --------- 339.0/455.9 MB 11.9 MB/s eta 0:00:10\n",
      "     --------------------------- --------- 339.5/455.9 MB 11.7 MB/s eta 0:00:10\n",
      "     --------------------------- --------- 340.0/455.9 MB 11.7 MB/s eta 0:00:10\n",
      "     --------------------------- --------- 340.6/455.9 MB 11.7 MB/s eta 0:00:10\n",
      "     --------------------------- --------- 341.1/455.9 MB 11.7 MB/s eta 0:00:10\n",
      "     --------------------------- --------- 341.6/455.9 MB 11.9 MB/s eta 0:00:10\n",
      "     --------------------------- --------- 342.1/455.9 MB 11.7 MB/s eta 0:00:10\n",
      "     --------------------------- --------- 342.7/455.9 MB 11.9 MB/s eta 0:00:10\n",
      "     --------------------------- --------- 343.2/455.9 MB 11.7 MB/s eta 0:00:10\n",
      "     --------------------------- --------- 343.7/455.9 MB 11.7 MB/s eta 0:00:10\n",
      "     --------------------------- --------- 344.3/455.9 MB 11.7 MB/s eta 0:00:10\n",
      "     --------------------------- --------- 344.8/455.9 MB 11.7 MB/s eta 0:00:10\n",
      "     ---------------------------- -------- 345.4/455.9 MB 11.7 MB/s eta 0:00:10\n",
      "     ---------------------------- -------- 345.9/455.9 MB 11.9 MB/s eta 0:00:10\n",
      "     ---------------------------- -------- 346.4/455.9 MB 11.9 MB/s eta 0:00:10\n",
      "     ---------------------------- -------- 346.8/455.9 MB 11.9 MB/s eta 0:00:10\n",
      "     ---------------------------- -------- 347.4/455.9 MB 11.7 MB/s eta 0:00:10\n",
      "     ---------------------------- -------- 348.0/455.9 MB 11.7 MB/s eta 0:00:10\n",
      "     ---------------------------- -------- 348.5/455.9 MB 11.7 MB/s eta 0:00:10\n",
      "     ---------------------------- -------- 349.0/455.9 MB 11.7 MB/s eta 0:00:10\n",
      "     ---------------------------- -------- 349.6/455.9 MB 11.7 MB/s eta 0:00:10\n",
      "     ---------------------------- -------- 350.1/455.9 MB 11.9 MB/s eta 0:00:09\n",
      "     ---------------------------- -------- 350.6/455.9 MB 11.9 MB/s eta 0:00:09\n",
      "     ---------------------------- -------- 351.2/455.9 MB 11.9 MB/s eta 0:00:09\n",
      "     ---------------------------- -------- 351.7/455.9 MB 11.9 MB/s eta 0:00:09\n",
      "     ---------------------------- -------- 352.2/455.9 MB 11.7 MB/s eta 0:00:09\n",
      "     ---------------------------- -------- 352.8/455.9 MB 11.7 MB/s eta 0:00:09\n",
      "     ---------------------------- -------- 353.3/455.9 MB 11.7 MB/s eta 0:00:09\n",
      "     ---------------------------- -------- 353.8/455.9 MB 11.7 MB/s eta 0:00:09\n",
      "     ---------------------------- -------- 354.3/455.9 MB 11.9 MB/s eta 0:00:09\n",
      "     ---------------------------- -------- 354.9/455.9 MB 11.7 MB/s eta 0:00:09\n",
      "     ---------------------------- -------- 355.4/455.9 MB 11.7 MB/s eta 0:00:09\n",
      "     ---------------------------- -------- 355.9/455.9 MB 11.9 MB/s eta 0:00:09\n",
      "     ---------------------------- -------- 356.5/455.9 MB 11.7 MB/s eta 0:00:09\n",
      "     ---------------------------- -------- 357.0/455.9 MB 11.7 MB/s eta 0:00:09\n",
      "     ----------------------------- ------- 357.5/455.9 MB 11.7 MB/s eta 0:00:09\n",
      "     ----------------------------- ------- 358.1/455.9 MB 11.7 MB/s eta 0:00:09\n",
      "     ----------------------------- ------- 358.6/455.9 MB 11.7 MB/s eta 0:00:09\n",
      "     ----------------------------- ------- 359.1/455.9 MB 11.7 MB/s eta 0:00:09\n",
      "     ----------------------------- ------- 359.7/455.9 MB 11.7 MB/s eta 0:00:09\n",
      "     ----------------------------- ------- 360.2/455.9 MB 11.9 MB/s eta 0:00:09\n",
      "     ----------------------------- ------- 360.7/455.9 MB 11.9 MB/s eta 0:00:09\n",
      "     ----------------------------- ------- 361.3/455.9 MB 11.9 MB/s eta 0:00:08\n",
      "     ----------------------------- ------- 361.8/455.9 MB 11.9 MB/s eta 0:00:08\n",
      "     ----------------------------- ------- 362.3/455.9 MB 11.7 MB/s eta 0:00:09\n",
      "     ----------------------------- ------- 362.9/455.9 MB 11.7 MB/s eta 0:00:08\n",
      "     ----------------------------- ------- 363.4/455.9 MB 11.7 MB/s eta 0:00:08\n",
      "     ----------------------------- ------- 363.9/455.9 MB 11.7 MB/s eta 0:00:08\n",
      "     ----------------------------- ------- 364.5/455.9 MB 11.7 MB/s eta 0:00:08\n",
      "     ----------------------------- ------- 365.0/455.9 MB 11.9 MB/s eta 0:00:08\n",
      "     ----------------------------- ------- 365.5/455.9 MB 11.9 MB/s eta 0:00:08\n",
      "     ----------------------------- ------- 366.1/455.9 MB 11.9 MB/s eta 0:00:08\n",
      "     ----------------------------- ------- 366.6/455.9 MB 11.9 MB/s eta 0:00:08\n",
      "     ----------------------------- ------- 367.1/455.9 MB 11.7 MB/s eta 0:00:08\n",
      "     ----------------------------- ------- 367.6/455.9 MB 11.7 MB/s eta 0:00:08\n",
      "     ----------------------------- ------- 368.2/455.9 MB 11.7 MB/s eta 0:00:08\n",
      "     ----------------------------- ------- 368.7/455.9 MB 11.7 MB/s eta 0:00:08\n",
      "     ----------------------------- ------- 369.2/455.9 MB 11.7 MB/s eta 0:00:08\n",
      "     ------------------------------ ------ 369.8/455.9 MB 11.9 MB/s eta 0:00:08\n",
      "     ------------------------------ ------ 370.3/455.9 MB 11.9 MB/s eta 0:00:08\n",
      "     ------------------------------ ------ 370.8/455.9 MB 11.9 MB/s eta 0:00:08\n",
      "     ------------------------------ ------ 371.3/455.9 MB 11.7 MB/s eta 0:00:08\n",
      "     ------------------------------ ------ 371.9/455.9 MB 11.7 MB/s eta 0:00:08\n",
      "     ------------------------------ ------ 372.3/455.9 MB 11.9 MB/s eta 0:00:08\n",
      "     ------------------------------ ------ 372.9/455.9 MB 11.7 MB/s eta 0:00:08\n",
      "     ------------------------------ ------ 373.5/455.9 MB 11.7 MB/s eta 0:00:08\n",
      "     ------------------------------ ------ 374.0/455.9 MB 11.9 MB/s eta 0:00:07\n",
      "     ------------------------------ ------ 374.5/455.9 MB 11.9 MB/s eta 0:00:07\n",
      "     ------------------------------ ------ 375.1/455.9 MB 11.9 MB/s eta 0:00:07\n",
      "     ------------------------------ ------ 375.6/455.9 MB 11.7 MB/s eta 0:00:07\n",
      "     ------------------------------ ------ 376.1/455.9 MB 11.7 MB/s eta 0:00:07\n",
      "     ------------------------------ ------ 376.7/455.9 MB 11.7 MB/s eta 0:00:07\n",
      "     ------------------------------ ------ 377.2/455.9 MB 11.7 MB/s eta 0:00:07\n",
      "     ------------------------------ ------ 377.7/455.9 MB 11.7 MB/s eta 0:00:07\n",
      "     ------------------------------ ------ 378.1/455.9 MB 11.7 MB/s eta 0:00:07\n",
      "     ------------------------------ ------ 378.7/455.9 MB 11.7 MB/s eta 0:00:07\n",
      "     ------------------------------ ------ 379.3/455.9 MB 11.7 MB/s eta 0:00:07\n",
      "     ------------------------------ ------ 379.8/455.9 MB 11.7 MB/s eta 0:00:07\n",
      "     ------------------------------ ------ 380.3/455.9 MB 11.7 MB/s eta 0:00:07\n",
      "     ------------------------------ ------ 380.9/455.9 MB 11.7 MB/s eta 0:00:07\n",
      "     ------------------------------ ------ 381.4/455.9 MB 11.7 MB/s eta 0:00:07\n",
      "     ------------------------------ ------ 381.9/455.9 MB 11.7 MB/s eta 0:00:07\n",
      "     ------------------------------- ----- 382.4/455.9 MB 11.7 MB/s eta 0:00:07\n",
      "     ------------------------------- ----- 383.0/455.9 MB 11.9 MB/s eta 0:00:07\n",
      "     ------------------------------- ----- 383.5/455.9 MB 11.9 MB/s eta 0:00:07\n",
      "     ------------------------------- ----- 384.0/455.9 MB 11.7 MB/s eta 0:00:07\n",
      "     ------------------------------- ----- 384.6/455.9 MB 11.7 MB/s eta 0:00:07\n",
      "     ------------------------------- ----- 385.0/455.9 MB 11.7 MB/s eta 0:00:07\n",
      "     ------------------------------- ----- 385.5/455.9 MB 11.7 MB/s eta 0:00:07\n",
      "     ------------------------------- ----- 386.0/455.9 MB 11.5 MB/s eta 0:00:07\n",
      "     ------------------------------- ----- 386.6/455.9 MB 11.5 MB/s eta 0:00:07\n",
      "     ------------------------------- ----- 387.1/455.9 MB 11.7 MB/s eta 0:00:06\n",
      "     ------------------------------- ----- 387.6/455.9 MB 11.7 MB/s eta 0:00:06\n",
      "     ------------------------------- ----- 388.1/455.9 MB 11.7 MB/s eta 0:00:06\n",
      "     ------------------------------- ----- 388.7/455.9 MB 11.7 MB/s eta 0:00:06\n",
      "     ------------------------------- ----- 389.2/455.9 MB 11.7 MB/s eta 0:00:06\n",
      "     ------------------------------- ----- 389.7/455.9 MB 11.7 MB/s eta 0:00:06\n",
      "     ------------------------------- ----- 390.3/455.9 MB 11.7 MB/s eta 0:00:06\n",
      "     ------------------------------- ----- 390.7/455.9 MB 11.7 MB/s eta 0:00:06\n",
      "     ------------------------------- ----- 391.3/455.9 MB 11.7 MB/s eta 0:00:06\n",
      "     ------------------------------- ----- 391.9/455.9 MB 11.7 MB/s eta 0:00:06\n",
      "     ------------------------------- ----- 392.4/455.9 MB 11.7 MB/s eta 0:00:06\n",
      "     ------------------------------- ----- 392.9/455.9 MB 11.7 MB/s eta 0:00:06\n",
      "     ------------------------------- ----- 393.4/455.9 MB 11.7 MB/s eta 0:00:06\n",
      "     ------------------------------- ----- 394.0/455.9 MB 11.7 MB/s eta 0:00:06\n",
      "     -------------------------------- ---- 394.5/455.9 MB 11.5 MB/s eta 0:00:06\n",
      "     -------------------------------- ---- 395.0/455.9 MB 11.5 MB/s eta 0:00:06\n",
      "     -------------------------------- ---- 395.6/455.9 MB 11.9 MB/s eta 0:00:06\n",
      "     -------------------------------- ---- 396.1/455.9 MB 11.9 MB/s eta 0:00:06\n",
      "     -------------------------------- ---- 396.6/455.9 MB 11.9 MB/s eta 0:00:05\n",
      "     -------------------------------- ---- 397.1/455.9 MB 11.7 MB/s eta 0:00:06\n",
      "     -------------------------------- ---- 397.7/455.9 MB 11.7 MB/s eta 0:00:05\n",
      "     -------------------------------- ---- 398.2/455.9 MB 11.7 MB/s eta 0:00:05\n",
      "     -------------------------------- ---- 398.8/455.9 MB 11.7 MB/s eta 0:00:05\n",
      "     -------------------------------- ---- 399.3/455.9 MB 11.7 MB/s eta 0:00:05\n",
      "     -------------------------------- ---- 399.8/455.9 MB 11.7 MB/s eta 0:00:05\n",
      "     -------------------------------- ---- 400.3/455.9 MB 11.9 MB/s eta 0:00:05\n",
      "     -------------------------------- ---- 400.9/455.9 MB 11.9 MB/s eta 0:00:05\n",
      "     -------------------------------- ---- 401.4/455.9 MB 11.9 MB/s eta 0:00:05\n",
      "     -------------------------------- ---- 401.9/455.9 MB 11.7 MB/s eta 0:00:05\n",
      "     -------------------------------- ---- 402.5/455.9 MB 11.7 MB/s eta 0:00:05\n",
      "     -------------------------------- ---- 402.6/455.9 MB 11.7 MB/s eta 0:00:05\n",
      "     -------------------------------- ---- 402.6/455.9 MB 11.7 MB/s eta 0:00:05\n",
      "     -------------------------------- ---- 402.6/455.9 MB 11.7 MB/s eta 0:00:05\n",
      "     -------------------------------- ---- 402.6/455.9 MB 11.7 MB/s eta 0:00:05\n",
      "     --------------------------------- ---- 403.1/455.9 MB 9.9 MB/s eta 0:00:06\n",
      "     --------------------------------- ---- 403.7/455.9 MB 9.9 MB/s eta 0:00:06\n",
      "     --------------------------------- ---- 404.2/455.9 MB 9.9 MB/s eta 0:00:06\n",
      "     --------------------------------- ---- 404.7/455.9 MB 9.9 MB/s eta 0:00:06\n",
      "     --------------------------------- ---- 405.3/455.9 MB 9.9 MB/s eta 0:00:06\n",
      "     --------------------------------- ---- 405.8/455.9 MB 9.9 MB/s eta 0:00:06\n",
      "     --------------------------------- ---- 406.3/455.9 MB 9.8 MB/s eta 0:00:06\n",
      "     --------------------------------- ---- 406.9/455.9 MB 9.8 MB/s eta 0:00:06\n",
      "     --------------------------------- ---- 407.4/455.9 MB 9.8 MB/s eta 0:00:05\n",
      "     ---------------------------------- --- 408.0/455.9 MB 9.8 MB/s eta 0:00:05\n",
      "     ---------------------------------- --- 408.5/455.9 MB 9.8 MB/s eta 0:00:05\n",
      "     ---------------------------------- --- 408.9/455.9 MB 9.9 MB/s eta 0:00:05\n",
      "     ---------------------------------- --- 408.9/455.9 MB 9.9 MB/s eta 0:00:05\n",
      "     ---------------------------------- --- 408.9/455.9 MB 9.9 MB/s eta 0:00:05\n",
      "     ---------------------------------- --- 409.1/455.9 MB 8.8 MB/s eta 0:00:06\n",
      "     ---------------------------------- --- 409.7/455.9 MB 8.8 MB/s eta 0:00:06\n",
      "     ---------------------------------- --- 410.2/455.9 MB 8.7 MB/s eta 0:00:06\n",
      "     ---------------------------------- --- 410.7/455.9 MB 8.7 MB/s eta 0:00:06\n",
      "     ---------------------------------- --- 411.3/455.9 MB 8.7 MB/s eta 0:00:06\n",
      "     ---------------------------------- --- 411.8/455.9 MB 8.7 MB/s eta 0:00:06\n",
      "     ---------------------------------- --- 412.3/455.9 MB 8.7 MB/s eta 0:00:05\n",
      "     ---------------------------------- --- 412.8/455.9 MB 8.8 MB/s eta 0:00:05\n",
      "     --------------------------------- --- 413.4/455.9 MB 10.4 MB/s eta 0:00:05\n",
      "     --------------------------------- --- 413.9/455.9 MB 10.4 MB/s eta 0:00:05\n",
      "     --------------------------------- --- 414.4/455.9 MB 10.2 MB/s eta 0:00:05\n",
      "     --------------------------------- --- 415.0/455.9 MB 10.2 MB/s eta 0:00:05\n",
      "     --------------------------------- --- 415.5/455.9 MB 10.2 MB/s eta 0:00:04\n",
      "     --------------------------------- --- 416.0/455.9 MB 10.2 MB/s eta 0:00:04\n",
      "     --------------------------------- --- 416.6/455.9 MB 10.2 MB/s eta 0:00:04\n",
      "     --------------------------------- --- 417.1/455.9 MB 10.2 MB/s eta 0:00:04\n",
      "     --------------------------------- --- 417.6/455.9 MB 10.4 MB/s eta 0:00:04\n",
      "     --------------------------------- --- 418.2/455.9 MB 10.4 MB/s eta 0:00:04\n",
      "     --------------------------------- --- 418.7/455.9 MB 10.2 MB/s eta 0:00:04\n",
      "     ---------------------------------- -- 419.2/455.9 MB 11.7 MB/s eta 0:00:04\n",
      "     ---------------------------------- -- 419.7/455.9 MB 11.7 MB/s eta 0:00:04\n",
      "     ---------------------------------- -- 420.3/455.9 MB 11.7 MB/s eta 0:00:04\n",
      "     ---------------------------------- -- 420.8/455.9 MB 11.7 MB/s eta 0:00:04\n",
      "     ---------------------------------- -- 421.3/455.9 MB 11.7 MB/s eta 0:00:03\n",
      "     ---------------------------------- -- 421.9/455.9 MB 11.9 MB/s eta 0:00:03\n",
      "     ---------------------------------- -- 422.4/455.9 MB 11.9 MB/s eta 0:00:03\n",
      "     ---------------------------------- -- 422.9/455.9 MB 11.9 MB/s eta 0:00:03\n",
      "     ---------------------------------- -- 423.5/455.9 MB 11.9 MB/s eta 0:00:03\n",
      "     ---------------------------------- -- 424.0/455.9 MB 11.9 MB/s eta 0:00:03\n",
      "     ---------------------------------- -- 424.5/455.9 MB 11.7 MB/s eta 0:00:03\n",
      "     ---------------------------------- -- 425.1/455.9 MB 11.7 MB/s eta 0:00:03\n",
      "     ---------------------------------- -- 425.6/455.9 MB 11.7 MB/s eta 0:00:03\n",
      "     ---------------------------------- -- 426.1/455.9 MB 11.7 MB/s eta 0:00:03\n",
      "     ---------------------------------- -- 426.6/455.9 MB 11.9 MB/s eta 0:00:03\n",
      "     ---------------------------------- -- 427.2/455.9 MB 11.9 MB/s eta 0:00:03\n",
      "     ---------------------------------- -- 427.7/455.9 MB 11.9 MB/s eta 0:00:03\n",
      "     ---------------------------------- -- 428.2/455.9 MB 11.9 MB/s eta 0:00:03\n",
      "     ---------------------------------- -- 428.8/455.9 MB 11.7 MB/s eta 0:00:03\n",
      "     ---------------------------------- -- 429.3/455.9 MB 11.7 MB/s eta 0:00:03\n",
      "     ---------------------------------- -- 429.8/455.9 MB 11.7 MB/s eta 0:00:03\n",
      "     ---------------------------------- -- 430.4/455.9 MB 11.7 MB/s eta 0:00:03\n",
      "     ---------------------------------- -- 430.9/455.9 MB 11.9 MB/s eta 0:00:03\n",
      "     ----------------------------------- - 431.4/455.9 MB 11.9 MB/s eta 0:00:03\n",
      "     ----------------------------------- - 432.0/455.9 MB 11.9 MB/s eta 0:00:03\n",
      "     ----------------------------------- - 432.5/455.9 MB 11.9 MB/s eta 0:00:02\n",
      "     ----------------------------------- - 433.0/455.9 MB 11.9 MB/s eta 0:00:02\n",
      "     ----------------------------------- - 433.1/455.9 MB 11.9 MB/s eta 0:00:02\n",
      "     ----------------------------------- - 433.1/455.9 MB 11.9 MB/s eta 0:00:02\n",
      "     ----------------------------------- - 433.1/455.9 MB 11.9 MB/s eta 0:00:02\n",
      "     ----------------------------------- - 433.1/455.9 MB 11.9 MB/s eta 0:00:02\n",
      "     ------------------------------------ - 433.2/455.9 MB 9.5 MB/s eta 0:00:03\n",
      "     ------------------------------------ - 433.7/455.9 MB 9.5 MB/s eta 0:00:03\n",
      "     ------------------------------------ - 434.2/455.9 MB 9.5 MB/s eta 0:00:03\n",
      "     ------------------------------------ - 434.8/455.9 MB 9.6 MB/s eta 0:00:03\n",
      "     ------------------------------------ - 435.3/455.9 MB 9.5 MB/s eta 0:00:03\n",
      "     ------------------------------------ - 435.8/455.9 MB 9.5 MB/s eta 0:00:03\n",
      "     ------------------------------------ - 436.3/455.9 MB 9.5 MB/s eta 0:00:03\n",
      "     ------------------------------------ - 436.9/455.9 MB 9.4 MB/s eta 0:00:03\n",
      "     ------------------------------------ - 437.4/455.9 MB 9.5 MB/s eta 0:00:02\n",
      "     ------------------------------------ - 437.9/455.9 MB 9.5 MB/s eta 0:00:02\n",
      "     ------------------------------------ - 438.5/455.9 MB 9.5 MB/s eta 0:00:02\n",
      "     ------------------------------------ - 439.0/455.9 MB 9.5 MB/s eta 0:00:02\n",
      "     ------------------------------------ - 439.5/455.9 MB 9.5 MB/s eta 0:00:02\n",
      "     ------------------------------------ - 440.1/455.9 MB 9.5 MB/s eta 0:00:02\n",
      "     ------------------------------------ - 440.6/455.9 MB 9.5 MB/s eta 0:00:02\n",
      "     ------------------------------------ - 441.1/455.9 MB 9.4 MB/s eta 0:00:02\n",
      "     ------------------------------------ - 441.6/455.9 MB 9.5 MB/s eta 0:00:02\n",
      "     ------------------------------------ - 442.2/455.9 MB 9.5 MB/s eta 0:00:02\n",
      "     ------------------------------------ - 442.7/455.9 MB 9.5 MB/s eta 0:00:02\n",
      "     ------------------------------------ - 443.2/455.9 MB 9.5 MB/s eta 0:00:02\n",
      "     ------------------------------------  443.8/455.9 MB 11.7 MB/s eta 0:00:02\n",
      "     ------------------------------------  444.3/455.9 MB 11.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  444.8/455.9 MB 11.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  445.4/455.9 MB 11.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  445.9/455.9 MB 11.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  446.4/455.9 MB 11.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  446.9/455.9 MB 11.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  447.5/455.9 MB 11.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  448.0/455.9 MB 11.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  448.5/455.9 MB 11.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  449.1/455.9 MB 11.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  449.6/455.9 MB 11.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  450.2/455.9 MB 11.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  450.7/455.9 MB 11.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  451.2/455.9 MB 11.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  451.8/455.9 MB 11.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  452.3/455.9 MB 11.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  452.8/455.9 MB 11.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  453.4/455.9 MB 11.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  453.9/455.9 MB 11.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  454.4/455.9 MB 11.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  455.0/455.9 MB 11.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  455.5/455.9 MB 11.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  455.9/455.9 MB 11.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  455.9/455.9 MB 11.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  455.9/455.9 MB 11.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  455.9/455.9 MB 11.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  455.9/455.9 MB 11.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  455.9/455.9 MB 11.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  455.9/455.9 MB 11.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  455.9/455.9 MB 11.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  455.9/455.9 MB 11.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  455.9/455.9 MB 11.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  455.9/455.9 MB 11.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  455.9/455.9 MB 11.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  455.9/455.9 MB 11.9 MB/s eta 0:00:01\n",
      "     -------------------------------------- 455.9/455.9 MB 5.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tensorflow-hub>=0.8.0 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow-text) (0.13.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (65.6.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (1.3.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (3.7.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (3.3.0)\n",
      "Collecting keras<2.11,>=2.10.0\n",
      "  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
      "     ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "     ------------ --------------------------- 0.5/1.7 MB 11.3 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 1.0/1.7 MB 12.9 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 1.6/1.7 MB 11.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.7/1.7 MB 10.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (0.4.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (0.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (4.5.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (23.3.3)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (1.6.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (1.42.0)\n",
      "Collecting tensorboard<2.11,>=2.10\n",
      "  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
      "     ---------------------------------------- 0.0/5.9 MB ? eta -:--:--\n",
      "     --- ------------------------------------ 0.5/5.9 MB 14.5 MB/s eta 0:00:01\n",
      "     ------ --------------------------------- 1.0/5.9 MB 12.5 MB/s eta 0:00:01\n",
      "     ---------- ----------------------------- 1.5/5.9 MB 12.1 MB/s eta 0:00:01\n",
      "     -------------- ------------------------- 2.1/5.9 MB 11.9 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 2.6/5.9 MB 11.7 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 3.1/5.9 MB 11.6 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 3.6/5.9 MB 11.4 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 4.1/5.9 MB 11.8 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 4.6/5.9 MB 11.8 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 5.2/5.9 MB 11.8 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 5.7/5.9 MB 11.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 5.9/5.9 MB 11.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (1.14.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (1.1.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (2.2.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (2.10.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (1.23.5)\n",
      "Requirement already satisfied: packaging in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (23.0)\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Using cached protobuf-3.19.6-cp310-cp310-win_amd64.whl (895 kB)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text) (16.0.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from astunparse>=1.6.0->tensorflow<2.11,>=2.10.0->tensorflow-text) (0.37.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (3.4.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (0.4.4)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (2.2.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (2.28.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (1.8.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text) (2.17.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: 'c:\\\\users\\\\tlrks\\\\anaconda3\\\\envs\\\\study\\\\lib\\\\site-packages\\\\tensorflow_estimator-2.10.0.dist-info\\\\METADATA'\n",
      "\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tensorflow-text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0427"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.10.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import TFBertModel\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFBertClassifier(tf.keras.Model):\n",
    "    def __init__(self, model_name, dir_path, num_class):\n",
    "        super(TFBertClassifier, self).__init__()\n",
    "\n",
    "        self.bert = TFBertModel.from_pretrained(model_name, cache_dir=dir_path)\n",
    "        self.dropout = tf.keras.layers.Dropout(self.bert.config.hidden_dropout_prob)\n",
    "        self.classifier = tf.keras.layers.Dense(\n",
    "            num_class, \n",
    "            kernel_initializer=tf.keras.initializers.TruncatedNormal(self.bert.config.initializer_range),\n",
    "            name=\"classifier\",\n",
    "        )\n",
    "\n",
    "    def call(self, inputs, attention_mask=None, token_type_ids=None, training=False):\n",
    "        # sequence output, pooled output, (hidden, attentions)로 출력\n",
    "        outputs = self.bert(\n",
    "            inputs, attention_mask=attention_mask, token_type_ids=token_type_ids\n",
    "        )\n",
    "        pooled_output = outputs[1]\n",
    "        pooled_output = self.dropout(pooled_output, training=training)\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8601bface4843d194d15ffc608bfef3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tlrks\\anaconda3\\envs\\study\\lib\\site-packages\\huggingface_hub\\file_download.py:123: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\tlrks\\Desktop\\workspace\\exercise\\BERT\\bert-ckpt. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c2af166f04c4a17b0bb07f0dc4da42c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.08G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-multilingual-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-multilingual-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "cls_model = TFBertClassifier(model_name=\"bert-base-multilingual-cased\",\n",
    "                             dir_path='bert-ckpt',\n",
    "                             num_class=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "\n",
    "cls_model.compile(optimizer=optimizer, loss=loss, metrics=[metric])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20년 4월 2일 종가 / 4월 3일 종가 / 4월 4일 종가\n",
    "기사데이터가 4월 3일 12시 데이터라면 -> 4월 3일 당일 종가를 가져옴 //\n",
    "15시40분 이전 데이터 -> 4월 2일종가랑 비교 -> 오르면 1, 떨어졌으면 0\n",
    "15시40분 이후 데이터 -> 4월 4일 종가랑 비교 -> 4일에 올랐으면 1, 떨어졌으면 0\n",
    "\n",
    "주가데이터프레임에서 row를 하나씩 가져옴 -> 다음 row랑 종가를 비교 -> 0인지, 1인지 결정\n",
    "4월 3일 종가를 가져왔고 다음날이 4월 6일로 되어 있으면, 4월 3일 15:40 이후, 4월 6일 15:40 이전의 기사들 데이터에 대해 위에서 결정한 라벨을 부여\n",
    "그다음은 4월 6일.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m text\n",
      "\u001b[1;31mNameError\u001b[0m: name 'text' is not defined"
     ]
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"D램, 낸드플래시 매출은 각각 37%, 31% ↓ / 中 파운드리 공장 2분기 2020년 말 양산 \\nSK하이닉스 이천 사업장. 연합뉴스 SK하이닉스의 지난해 매출액이 전년 대비 33% 감소했지만, 비메모리 반도체 매출은 50%가량 증가한 것으로 나타났다. 31일 SK하이닉스의 사업보고서에 따르면, 2019년 D램 매출은 20조3000억원으로 전년과 비교해 37% 감소했고, 낸드플래시 매출은 5조1000억원으로 31% 줄어든 것으로 집계됐다. 반면 비메모리 사업을 포함한 기타 항목 매출은 2018년 6500억원에서 지난해 1조6000억원으로 2배 이상 증가했다. 지난해 기타 매출 가운데는 SK하이닉스가 2018년 12월 지분 100%를 인수한 사회적기업 행복나래 등 자회사 매출 약 7000억원이 포함됐다. 나머지 매출 약 8000억원은 이미지센서 부문과 파운드리 자회사 SK하이닉스시스템IC 등 비메모리 반도체 사업으로, 2018년(5500억여원) 대비 성장한 것으로 파악된다. 이에 따라 D램 부문 매출 비중은 2018년 80%에서 지난해 75%로 줄어들었고, 기타 항목 비중은 같은 기간 2%에서 6%로 확대됐다. SK하이닉스가 주력하는 분야는 비메모리 사업 중에서도 모바일, 노트북용 이미지센서 시장이다. 지난해 일본에 차세대 CIS(CMOS 이미지센서) 연구개발센터를 여는 등 시장 점유율 확대를 위한 제품 개발에 주력하고 있다. 올해는 모든 CIS 제품을 '블랙펄(Black Pearl)'로 공식 브랜딩하고, 하반기 중 픽셀 크기로 4800만화소를 구현한 제품도 선보인다는 계획이다. SK하이닉스시스템IC는 중국 장쑤성 우시에서 합작법인을 설립해 파운드리 공장을 건설하고 있다. 올해 2분기 내 준공되면 연말 양산이 목표다. SK하이닉스는 이날 매그나칩반도체의 파운드리(반도체 위탁생산) 부문도 인수했다. 박세준 기자 세상을 보는 눈, 세계일보\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = data.content.values[0]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D램  낸드플래시 매출은 각각 37   31        파운드리 공장 2분기 2020년 말 양산  SK하이닉스 이천 사업장  연합뉴스 SK하이닉스의 지난해 매출액이 전년 대비 33  감소했지만  비메모리 반도체 매출은 50 가량 증가한 것으로 나타났다  31일 SK하이닉스의 사업보고서에 따르면  2019년 D램 매출은 20조3000억원으로 전년과 비교해 37  감소했고  낸드플래시 매출은 5조1000억원으로 31  줄어든 것으로 집계됐다  반면 비메모리 사업을 포함한 기타 항목 매출은 2018년 6500억원에서 지난해 1조6000억원으로 2배 이상 증가했다  지난해 기타 매출 가운데는 SK하이닉스가 2018년 12월 지분 100 를 인수한 사회적기업 행복나래 등 자회사 매출 약 7000억원이 포함됐다  나머지 매출 약 8000억원은 이미지센서 부문과 파운드리 자회사 SK하이닉스시스템IC 등 비메모리 반도체 사업으로  2018년 5500억여원  대비 성장한 것으로 파악된다  이에 따라 D램 부문 매출 비중은 2018년 80 에서 지난해 75 로 줄어들었고  기타 항목 비중은 같은 기간 2 에서 6 로 확대됐다  SK하이닉스가 주력하는 분야는 비메모리 사업 중에서도 모바일  노트북용 이미지센서 시장이다  지난해 일본에 차세대 CIS CMOS 이미지센서  연구개발센터를 여는 등 시장 점유율 확대를 위한 제품 개발에 주력하고 있다  올해는 모든 CIS 제품을  블랙펄 Black Pearl  로 공식 브랜딩하고  하반기 중 픽셀 크기로 4800만화소를 구현한 제품도 선보인다는 계획이다  SK하이닉스시스템IC는 중국 장쑤성 우시에서 합작법인을 설립해 파운드리 공장을 건설하고 있다  올해 2분기 내 준공되면 연말 양산이 목표다  SK하이닉스는 이날 매그나칩반도체의 파운드리 반도체 위탁생산  부문도 인수했다  박세준 기자 세상을 보는 눈  세계일보'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttt = re.sub('↓', '하락', text)\n",
    "ttt\n",
    "\n",
    "# ttt = re.sub('[^가-힣a-zA-z0-9 ]', ' ', text)\n",
    "# ttt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D',\n",
       " '##램',\n",
       " ',',\n",
       " '낸',\n",
       " '##드',\n",
       " '##플',\n",
       " '##래',\n",
       " '##시',\n",
       " '매출',\n",
       " '##은',\n",
       " '각각',\n",
       " '37',\n",
       " '%',\n",
       " ',',\n",
       " '31',\n",
       " '%',\n",
       " '↓',\n",
       " '/',\n",
       " '中',\n",
       " '파',\n",
       " '##운드',\n",
       " '##리',\n",
       " '공장',\n",
       " '2',\n",
       " '##분기',\n",
       " '2020년',\n",
       " '말',\n",
       " '양산',\n",
       " 'SK',\n",
       " '##하이',\n",
       " '##닉',\n",
       " '##스',\n",
       " '이',\n",
       " '##천',\n",
       " '사업',\n",
       " '##장',\n",
       " '.',\n",
       " '연합',\n",
       " '##뉴스',\n",
       " 'SK',\n",
       " '##하이',\n",
       " '##닉',\n",
       " '##스의',\n",
       " '지난해',\n",
       " '매출',\n",
       " '##액이',\n",
       " '전년',\n",
       " '대비',\n",
       " '33',\n",
       " '%',\n",
       " '감소',\n",
       " '##했지만',\n",
       " ',',\n",
       " '비',\n",
       " '##메',\n",
       " '##모',\n",
       " '##리',\n",
       " '반도체',\n",
       " '매출',\n",
       " '##은',\n",
       " '50',\n",
       " '%',\n",
       " '가',\n",
       " '##량',\n",
       " '증가',\n",
       " '##한',\n",
       " '것으로',\n",
       " '나타났다',\n",
       " '.',\n",
       " '31일',\n",
       " 'SK',\n",
       " '##하이',\n",
       " '##닉',\n",
       " '##스의',\n",
       " '사업',\n",
       " '##보고',\n",
       " '##서에',\n",
       " '따르면',\n",
       " ',',\n",
       " '2019년',\n",
       " 'D',\n",
       " '##램',\n",
       " '매출',\n",
       " '##은',\n",
       " '20',\n",
       " '##조',\n",
       " '##30',\n",
       " '##00',\n",
       " '##억원',\n",
       " '##으로',\n",
       " '전년',\n",
       " '##과',\n",
       " '비교',\n",
       " '##해',\n",
       " '37',\n",
       " '%',\n",
       " '감소',\n",
       " '##했고',\n",
       " ',',\n",
       " '낸',\n",
       " '##드',\n",
       " '##플',\n",
       " '##래',\n",
       " '##시',\n",
       " '매출',\n",
       " '##은',\n",
       " '5',\n",
       " '##조',\n",
       " '##100',\n",
       " '##0',\n",
       " '##억원',\n",
       " '##으로',\n",
       " '31',\n",
       " '%',\n",
       " '줄어',\n",
       " '##든',\n",
       " '것으로',\n",
       " '집계',\n",
       " '##됐다',\n",
       " '.',\n",
       " '반면',\n",
       " '비',\n",
       " '##메',\n",
       " '##모',\n",
       " '##리',\n",
       " '사업을',\n",
       " '포함한',\n",
       " '기타',\n",
       " '항',\n",
       " '##목',\n",
       " '매출',\n",
       " '##은',\n",
       " '2018년',\n",
       " '65',\n",
       " '##00',\n",
       " '##억원',\n",
       " '##에서',\n",
       " '지난해',\n",
       " '1조',\n",
       " '##60',\n",
       " '##00',\n",
       " '##억원',\n",
       " '##으로',\n",
       " '2',\n",
       " '##배',\n",
       " '이상',\n",
       " '증가',\n",
       " '##했다',\n",
       " '.',\n",
       " '지난해',\n",
       " '기타',\n",
       " '매출',\n",
       " '가운데',\n",
       " '##는',\n",
       " 'SK',\n",
       " '##하이',\n",
       " '##닉',\n",
       " '##스가',\n",
       " '2018년',\n",
       " '12월',\n",
       " '지분',\n",
       " '100',\n",
       " '%',\n",
       " '를',\n",
       " '인수',\n",
       " '##한',\n",
       " '사회적',\n",
       " '##기업',\n",
       " '행복',\n",
       " '##나',\n",
       " '##래',\n",
       " '등',\n",
       " '자',\n",
       " '##회사',\n",
       " '매출',\n",
       " '약',\n",
       " '70',\n",
       " '##00',\n",
       " '##억원',\n",
       " '##이',\n",
       " '포함',\n",
       " '##됐다',\n",
       " '.',\n",
       " '나머지',\n",
       " '매출',\n",
       " '약',\n",
       " '800',\n",
       " '##0',\n",
       " '##억원',\n",
       " '##은',\n",
       " '이미지',\n",
       " '##센',\n",
       " '##서',\n",
       " '부문',\n",
       " '##과',\n",
       " '파',\n",
       " '##운드',\n",
       " '##리',\n",
       " '자',\n",
       " '##회사',\n",
       " 'SK',\n",
       " '##하이',\n",
       " '##닉',\n",
       " '##스',\n",
       " '##시스템',\n",
       " '##I',\n",
       " '##C',\n",
       " '등',\n",
       " '비',\n",
       " '##메',\n",
       " '##모',\n",
       " '##리',\n",
       " '반도체',\n",
       " '사업',\n",
       " '##으로',\n",
       " ',',\n",
       " '2018년',\n",
       " '(',\n",
       " '55',\n",
       " '##00',\n",
       " '##억',\n",
       " '##여',\n",
       " '##원',\n",
       " ')',\n",
       " '대비',\n",
       " '성장',\n",
       " '##한',\n",
       " '것으로',\n",
       " '파악',\n",
       " '##된다',\n",
       " '.',\n",
       " '이에',\n",
       " '따라',\n",
       " 'D',\n",
       " '##램',\n",
       " '부문',\n",
       " '매출',\n",
       " '비중',\n",
       " '##은',\n",
       " '2018년',\n",
       " '80',\n",
       " '%',\n",
       " '에서',\n",
       " '지난해',\n",
       " '75',\n",
       " '%',\n",
       " '로',\n",
       " '줄어들',\n",
       " '##었고',\n",
       " ',',\n",
       " '기타',\n",
       " '항',\n",
       " '##목',\n",
       " '비중',\n",
       " '##은',\n",
       " '같은',\n",
       " '기간',\n",
       " '2',\n",
       " '%',\n",
       " '에서',\n",
       " '6',\n",
       " '%',\n",
       " '로',\n",
       " '확대',\n",
       " '##됐다',\n",
       " '.',\n",
       " 'SK',\n",
       " '##하이',\n",
       " '##닉',\n",
       " '##스가',\n",
       " '주',\n",
       " '##력',\n",
       " '##하는',\n",
       " '분야',\n",
       " '##는',\n",
       " '비',\n",
       " '##메',\n",
       " '##모',\n",
       " '##리',\n",
       " '사업',\n",
       " '중에서',\n",
       " '##도',\n",
       " '모바일',\n",
       " ',',\n",
       " '노트',\n",
       " '##북',\n",
       " '##용',\n",
       " '이미지',\n",
       " '##센',\n",
       " '##서',\n",
       " '시장이',\n",
       " '##다',\n",
       " '.',\n",
       " '지난해',\n",
       " '일본에',\n",
       " '차',\n",
       " '##세대',\n",
       " 'C',\n",
       " '##I',\n",
       " '##S',\n",
       " '(',\n",
       " 'C',\n",
       " '##M',\n",
       " '##O',\n",
       " '##S',\n",
       " '이미지',\n",
       " '##센',\n",
       " '##서',\n",
       " ')',\n",
       " '연구',\n",
       " '##개발',\n",
       " '##센터',\n",
       " '##를',\n",
       " '여',\n",
       " '##는',\n",
       " '등',\n",
       " '시장',\n",
       " '점유',\n",
       " '##율',\n",
       " '확대',\n",
       " '##를',\n",
       " '위한',\n",
       " '제품',\n",
       " '개발',\n",
       " '##에',\n",
       " '주',\n",
       " '##력',\n",
       " '##하고',\n",
       " '있다',\n",
       " '.',\n",
       " '올해',\n",
       " '##는',\n",
       " '모든',\n",
       " 'C',\n",
       " '##I',\n",
       " '##S',\n",
       " '제품을',\n",
       " \"'\",\n",
       " '블랙',\n",
       " '##펄',\n",
       " '(',\n",
       " 'B',\n",
       " '##l',\n",
       " '##ac',\n",
       " '##k',\n",
       " 'P',\n",
       " '##e',\n",
       " '##ar',\n",
       " '##l',\n",
       " ')',\n",
       " \"'\",\n",
       " '로',\n",
       " '공식',\n",
       " '브',\n",
       " '##랜',\n",
       " '##딩',\n",
       " '##하고',\n",
       " ',',\n",
       " '하',\n",
       " '##반기',\n",
       " '중',\n",
       " '픽',\n",
       " '##셀',\n",
       " '크',\n",
       " '##기로',\n",
       " '48',\n",
       " '##00만',\n",
       " '##화',\n",
       " '##소를',\n",
       " '구',\n",
       " '##현',\n",
       " '##한',\n",
       " '제품',\n",
       " '##도',\n",
       " '선보',\n",
       " '##인다',\n",
       " '##는',\n",
       " '계획이다',\n",
       " '.',\n",
       " 'SK',\n",
       " '##하이',\n",
       " '##닉',\n",
       " '##스',\n",
       " '##시스템',\n",
       " '##I',\n",
       " '##C',\n",
       " '##는',\n",
       " '중국',\n",
       " '장',\n",
       " '##쑤',\n",
       " '##성',\n",
       " '우',\n",
       " '##시에',\n",
       " '##서',\n",
       " '합작',\n",
       " '##법인',\n",
       " '##을',\n",
       " '설립',\n",
       " '##해',\n",
       " '파',\n",
       " '##운드',\n",
       " '##리',\n",
       " '공장',\n",
       " '##을',\n",
       " '건설',\n",
       " '##하고',\n",
       " '있다',\n",
       " '.',\n",
       " '올해',\n",
       " '2',\n",
       " '##분기',\n",
       " '내',\n",
       " '준',\n",
       " '##공',\n",
       " '##되면',\n",
       " '연말',\n",
       " '양산',\n",
       " '##이',\n",
       " '목표',\n",
       " '##다',\n",
       " '.',\n",
       " 'SK',\n",
       " '##하이',\n",
       " '##닉',\n",
       " '##스는',\n",
       " '이날',\n",
       " '매',\n",
       " '##그',\n",
       " '##나',\n",
       " '##칩',\n",
       " '##반도',\n",
       " '##체의',\n",
       " '파',\n",
       " '##운드',\n",
       " '##리',\n",
       " '(',\n",
       " '반도체',\n",
       " '위',\n",
       " '##탁',\n",
       " '##생산',\n",
       " ')',\n",
       " '부문',\n",
       " '##도',\n",
       " '인수',\n",
       " '##했다',\n",
       " '.',\n",
       " '박',\n",
       " '##세',\n",
       " '##준',\n",
       " '기자',\n",
       " '세상을',\n",
       " '보는',\n",
       " '눈',\n",
       " ',',\n",
       " '세계',\n",
       " '##일보']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "60개 문서가 있으면 0, 1 결과 60개\n",
    "얘를 평균"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
